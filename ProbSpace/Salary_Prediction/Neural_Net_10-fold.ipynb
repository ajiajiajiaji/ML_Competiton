{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./input/train_data.csv\")\n",
    "test_df = pd.read_csv(\"./input/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape： (21000, 13)\n",
      "test shape： (9000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape：\", train_df.shape)\n",
    "print(\"test shape：\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "def preprocess(df):\n",
    "    df[\"area\"] = LabelEncoder().fit_transform(df[\"area\"])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_eng(df):\n",
    "    #数値系\n",
    "    #家族の人数\n",
    "    df[\"family_num\"] = df[\"partner\"] + df[\"num_child\"]\n",
    "    \n",
    "    #年間の勤務時間\n",
    "    df[\"work_time_per_year\"] = 8*245*df[\"service_length\"] + 12*df[\"overtime\"]*df[\"service_length\"]\n",
    "    \n",
    "    #自由時間\n",
    "    df[\"free_time_per_year\"] = 24*365 - 8*365 - df[\"study_time\"]*48 - df[\"overtime\"]*12 - df[\"commute\"]*365\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 ms, sys: 8.32 ms, total: 36.5 ms\n",
      "Wall time: 38.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = preprocess(train_df)\n",
    "train_df = fea_eng(train_df)\n",
    "\n",
    "test_df = preprocess(test_df)\n",
    "test_df = fea_eng(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>partner</th>\n",
       "      <th>num_child</th>\n",
       "      <th>education</th>\n",
       "      <th>service_length</th>\n",
       "      <th>study_time</th>\n",
       "      <th>commute</th>\n",
       "      <th>overtime</th>\n",
       "      <th>salary</th>\n",
       "      <th>family_num</th>\n",
       "      <th>work_time_per_year</th>\n",
       "      <th>free_time_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>428.074887</td>\n",
       "      <td>3</td>\n",
       "      <td>49689.6</td>\n",
       "      <td>5049.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>317.930517</td>\n",
       "      <td>0</td>\n",
       "      <td>27414.4</td>\n",
       "      <td>5003.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>357.350316</td>\n",
       "      <td>0</td>\n",
       "      <td>30279.2</td>\n",
       "      <td>5299.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>201.310911</td>\n",
       "      <td>0</td>\n",
       "      <td>8132.8</td>\n",
       "      <td>5476.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>178.067475</td>\n",
       "      <td>0</td>\n",
       "      <td>10094.0</td>\n",
       "      <td>5564.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  position  age  area  sex  partner  num_child  education  \\\n",
       "0   0         1   44    24    2        1          2          1   \n",
       "1   1         2   31    10    1        0          0          0   \n",
       "2   2         2   36    14    1        0          0          2   \n",
       "3   3         0   22    26    2        0          0          0   \n",
       "4   4         0   25    46    2        0          0          1   \n",
       "\n",
       "   service_length  study_time  commute  overtime      salary  family_num  \\\n",
       "0              24         2.0      1.6       9.2  428.074887           3   \n",
       "1              13         9.0      0.7      12.4  317.930517           0   \n",
       "2              14         4.0      0.4      16.9  357.350316           0   \n",
       "3               4         3.0      0.4       6.1  201.310911           0   \n",
       "4               5         3.0      0.2       4.9  178.067475           0   \n",
       "\n",
       "   work_time_per_year  free_time_per_year  \n",
       "0             49689.6              5049.6  \n",
       "1             27414.4              5003.7  \n",
       "2             30279.2              5299.2  \n",
       "3              8132.8              5476.8  \n",
       "4             10094.0              5564.2  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>partner</th>\n",
       "      <th>num_child</th>\n",
       "      <th>education</th>\n",
       "      <th>service_length</th>\n",
       "      <th>study_time</th>\n",
       "      <th>commute</th>\n",
       "      <th>overtime</th>\n",
       "      <th>family_num</th>\n",
       "      <th>work_time_per_year</th>\n",
       "      <th>free_time_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6</td>\n",
       "      <td>40477.6</td>\n",
       "      <td>4964.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5434.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3975.2</td>\n",
       "      <td>5278.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19600.0</td>\n",
       "      <td>5586.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>47867.6</td>\n",
       "      <td>5392.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  position  age  area  sex  partner  num_child  education  \\\n",
       "0   0         3   39    46    2        1          5          1   \n",
       "1   1         1   31    11    1        0          0          4   \n",
       "2   2         0   20    24    2        1          2          0   \n",
       "3   3         0   28     0    2        0          0          0   \n",
       "4   4         1   41    23    2        0          0          0   \n",
       "\n",
       "   service_length  study_time  commute  overtime  family_num  \\\n",
       "0              19         1.0      1.8      14.2           6   \n",
       "1               0         0.0      0.5      18.6           0   \n",
       "2               2         2.0      1.2       2.3           3   \n",
       "3              10         3.0      0.3       0.0           0   \n",
       "4              23         3.0      0.5      10.1           0   \n",
       "\n",
       "   work_time_per_year  free_time_per_year  \n",
       "0             40477.6              4964.6  \n",
       "1                 0.0              5434.3  \n",
       "2              3975.2              5278.4  \n",
       "3             19600.0              5586.5  \n",
       "4             47867.6              5392.3  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['id', 'salary', \"position\", \"area\", \"sex\", \"partner\", \"education\", \"age_generation\"]]\n",
    "target = train_df[\"salary\"]\n",
    "target = target.map(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train_df[features].values)\n",
    "test = scaler.fit_transform(test_df[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 2s 123us/step - loss: 2.8206 - mae: 1.1884 - val_loss: 0.7266 - val_mae: 0.6391\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.3757 - mae: 0.4573 - val_loss: 0.0850 - val_mae: 0.2116\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.1493 - mae: 0.3026 - val_loss: 0.0458 - val_mae: 0.1673\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.1203 - mae: 0.2718 - val_loss: 0.0390 - val_mae: 0.1445\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.1102 - mae: 0.2624 - val_loss: 0.0313 - val_mae: 0.1355\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.1007 - mae: 0.2498 - val_loss: 0.0278 - val_mae: 0.1269\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0929 - mae: 0.2398 - val_loss: 0.0276 - val_mae: 0.1278\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0876 - mae: 0.2333 - val_loss: 0.0256 - val_mae: 0.1245\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0816 - mae: 0.2255 - val_loss: 0.0271 - val_mae: 0.1288\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0821 - mae: 0.2257 - val_loss: 0.0277 - val_mae: 0.1299\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0798 - mae: 0.2233 - val_loss: 0.0292 - val_mae: 0.1351\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0752 - mae: 0.2162 - val_loss: 0.0332 - val_mae: 0.1465\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0733 - mae: 0.2137 - val_loss: 0.0221 - val_mae: 0.1147\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0708 - mae: 0.2106 - val_loss: 0.0205 - val_mae: 0.1101\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0690 - mae: 0.2075 - val_loss: 0.0233 - val_mae: 0.1153\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0674 - mae: 0.2049 - val_loss: 0.0238 - val_mae: 0.1173\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0665 - mae: 0.2043 - val_loss: 0.0206 - val_mae: 0.1110\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0643 - mae: 0.1999 - val_loss: 0.0244 - val_mae: 0.1191\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0649 - mae: 0.2007 - val_loss: 0.0227 - val_mae: 0.1174\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0610 - mae: 0.1946 - val_loss: 0.0203 - val_mae: 0.1107\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0603 - mae: 0.1943 - val_loss: 0.0227 - val_mae: 0.1176\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0584 - mae: 0.1909 - val_loss: 0.0194 - val_mae: 0.1086\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0562 - mae: 0.1874 - val_loss: 0.0251 - val_mae: 0.1257\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0586 - mae: 0.1911 - val_loss: 0.0455 - val_mae: 0.1795\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0566 - mae: 0.1883 - val_loss: 0.0195 - val_mae: 0.1077\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0547 - mae: 0.1836 - val_loss: 0.0219 - val_mae: 0.1171\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0542 - mae: 0.1836 - val_loss: 0.0188 - val_mae: 0.1055\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0536 - mae: 0.1821 - val_loss: 0.0361 - val_mae: 0.1571\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0530 - mae: 0.1820 - val_loss: 0.0188 - val_mae: 0.1071\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0512 - mae: 0.1786 - val_loss: 0.0236 - val_mae: 0.1189\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0491 - mae: 0.1744 - val_loss: 0.0175 - val_mae: 0.1026\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0491 - mae: 0.1747 - val_loss: 0.0206 - val_mae: 0.1094\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0483 - mae: 0.1737 - val_loss: 0.0235 - val_mae: 0.1219\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0501 - mae: 0.1764 - val_loss: 0.0170 - val_mae: 0.1013\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0472 - mae: 0.1707 - val_loss: 0.0223 - val_mae: 0.1179\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0471 - mae: 0.1711 - val_loss: 0.0216 - val_mae: 0.1110\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0467 - mae: 0.1702 - val_loss: 0.0194 - val_mae: 0.1078\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0443 - mae: 0.1662 - val_loss: 0.0223 - val_mae: 0.1183\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0445 - mae: 0.1659 - val_loss: 0.0159 - val_mae: 0.0957\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0454 - mae: 0.1678 - val_loss: 0.0239 - val_mae: 0.1207\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0451 - mae: 0.1675 - val_loss: 0.0170 - val_mae: 0.1003\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0444 - mae: 0.1655 - val_loss: 0.0173 - val_mae: 0.1010\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0425 - mae: 0.1621 - val_loss: 0.0172 - val_mae: 0.0995\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0432 - mae: 0.1631 - val_loss: 0.0201 - val_mae: 0.1107\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0431 - mae: 0.1645 - val_loss: 0.0194 - val_mae: 0.1079\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0423 - mae: 0.1621 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0426 - mae: 0.1629 - val_loss: 0.0307 - val_mae: 0.1368\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0428 - mae: 0.1626 - val_loss: 0.0177 - val_mae: 0.1017\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0417 - mae: 0.1611 - val_loss: 0.0170 - val_mae: 0.0996\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0425 - mae: 0.1623 - val_loss: 0.0204 - val_mae: 0.1117\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0421 - mae: 0.1615 - val_loss: 0.0153 - val_mae: 0.0950\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0401 - mae: 0.1577 - val_loss: 0.0187 - val_mae: 0.1058\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0408 - mae: 0.1588 - val_loss: 0.0228 - val_mae: 0.1186\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0409 - mae: 0.1586 - val_loss: 0.0156 - val_mae: 0.0956\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0411 - mae: 0.1591 - val_loss: 0.0161 - val_mae: 0.0962\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0408 - mae: 0.1582 - val_loss: 0.0160 - val_mae: 0.0955\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0405 - mae: 0.1590 - val_loss: 0.0156 - val_mae: 0.0947\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0394 - mae: 0.1559 - val_loss: 0.0172 - val_mae: 0.1016\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0383 - mae: 0.1543 - val_loss: 0.0157 - val_mae: 0.0963\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0395 - mae: 0.1560 - val_loss: 0.0176 - val_mae: 0.1025\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0391 - mae: 0.1559 - val_loss: 0.0247 - val_mae: 0.1207\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0400 - mae: 0.1577 - val_loss: 0.0164 - val_mae: 0.0976\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0392 - mae: 0.1555 - val_loss: 0.0165 - val_mae: 0.0986\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0385 - mae: 0.1544 - val_loss: 0.0153 - val_mae: 0.0944\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0379 - mae: 0.1529 - val_loss: 0.0160 - val_mae: 0.0953\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 45us/step - loss: 0.0386 - mae: 0.1546 - val_loss: 0.0153 - val_mae: 0.0944\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0376 - mae: 0.1521 - val_loss: 0.0185 - val_mae: 0.1047\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0379 - mae: 0.1528 - val_loss: 0.0160 - val_mae: 0.0974\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0373 - mae: 0.1522 - val_loss: 0.0170 - val_mae: 0.0996\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0377 - mae: 0.1527 - val_loss: 0.0173 - val_mae: 0.1007\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0367 - mae: 0.1503 - val_loss: 0.0164 - val_mae: 0.0993\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0368 - mae: 0.1512 - val_loss: 0.0158 - val_mae: 0.0964\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0379 - mae: 0.1529 - val_loss: 0.0174 - val_mae: 0.1018\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0361 - mae: 0.1490 - val_loss: 0.0155 - val_mae: 0.0948\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0363 - mae: 0.1496 - val_loss: 0.0151 - val_mae: 0.0939\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0367 - mae: 0.1507 - val_loss: 0.0154 - val_mae: 0.0946\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0357 - mae: 0.1485 - val_loss: 0.0160 - val_mae: 0.0968\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0363 - mae: 0.1501 - val_loss: 0.0157 - val_mae: 0.0950\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0369 - mae: 0.1511 - val_loss: 0.0162 - val_mae: 0.0966\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0350 - mae: 0.1471 - val_loss: 0.0180 - val_mae: 0.1044\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0351 - mae: 0.1476 - val_loss: 0.0160 - val_mae: 0.0967\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 2s 99us/step - loss: 0.0353 - mae: 0.1474 - val_loss: 0.0160 - val_mae: 0.0974\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 2s 103us/step - loss: 0.0356 - mae: 0.1483 - val_loss: 0.0187 - val_mae: 0.1062\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0354 - mae: 0.1476 - val_loss: 0.0154 - val_mae: 0.0954\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0346 - mae: 0.1461 - val_loss: 0.0157 - val_mae: 0.0957\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.0346 - mae: 0.1458 - val_loss: 0.0153 - val_mae: 0.0945\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0349 - mae: 0.1468 - val_loss: 0.0156 - val_mae: 0.0954\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0347 - mae: 0.1457 - val_loss: 0.0171 - val_mae: 0.1004\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0341 - mae: 0.1448 - val_loss: 0.0158 - val_mae: 0.0967\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0342 - mae: 0.1454 - val_loss: 0.0175 - val_mae: 0.1009\n",
      "Epoch 91/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0341 - mae: 0.1452 - val_loss: 0.0156 - val_mae: 0.0959\n",
      "Epoch 92/100\n",
      "18900/18900 [==============================] - 1s 46us/step - loss: 0.0338 - mae: 0.1448 - val_loss: 0.0153 - val_mae: 0.0940\n",
      "Epoch 93/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0336 - mae: 0.1439 - val_loss: 0.0158 - val_mae: 0.0966\n",
      "Epoch 94/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0329 - mae: 0.1421 - val_loss: 0.0154 - val_mae: 0.0941\n",
      "Epoch 95/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0329 - mae: 0.1420 - val_loss: 0.0157 - val_mae: 0.0949\n",
      "Fold 2\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 3s 183us/step - loss: 2.7450 - mae: 1.1685 - val_loss: 0.6617 - val_mae: 0.5950\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.3561 - mae: 0.4474 - val_loss: 0.0939 - val_mae: 0.2309\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.1513 - mae: 0.3038 - val_loss: 0.0399 - val_mae: 0.1482\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.1216 - mae: 0.2740 - val_loss: 0.0344 - val_mae: 0.1404\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1099 - mae: 0.2614 - val_loss: 0.0397 - val_mae: 0.1561\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.1010 - mae: 0.2500 - val_loss: 0.0296 - val_mae: 0.1303\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0936 - mae: 0.2409 - val_loss: 0.0266 - val_mae: 0.1243\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0871 - mae: 0.2329 - val_loss: 0.0355 - val_mae: 0.1497\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0860 - mae: 0.2318 - val_loss: 0.0342 - val_mae: 0.1426\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0831 - mae: 0.2281 - val_loss: 0.0272 - val_mae: 0.1302\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0793 - mae: 0.2227 - val_loss: 0.0233 - val_mae: 0.1185\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0771 - mae: 0.2189 - val_loss: 0.0220 - val_mae: 0.1153\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0750 - mae: 0.2162 - val_loss: 0.0271 - val_mae: 0.1295\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0741 - mae: 0.2149 - val_loss: 0.0237 - val_mae: 0.1211\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0723 - mae: 0.2121 - val_loss: 0.0405 - val_mae: 0.1637\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0685 - mae: 0.2061 - val_loss: 0.0216 - val_mae: 0.1133\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0664 - mae: 0.2030 - val_loss: 0.0232 - val_mae: 0.1175\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0648 - mae: 0.2011 - val_loss: 0.0198 - val_mae: 0.1081\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0632 - mae: 0.1990 - val_loss: 0.0188 - val_mae: 0.1049\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0636 - mae: 0.1994 - val_loss: 0.0263 - val_mae: 0.1309\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0620 - mae: 0.1963 - val_loss: 0.0186 - val_mae: 0.1048\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0601 - mae: 0.1932 - val_loss: 0.0205 - val_mae: 0.1107\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 2s 126us/step - loss: 0.0604 - mae: 0.1944 - val_loss: 0.0182 - val_mae: 0.1042\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 2s 117us/step - loss: 0.0575 - mae: 0.1892 - val_loss: 0.0193 - val_mae: 0.1075\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0568 - mae: 0.1883 - val_loss: 0.0171 - val_mae: 0.1003\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0577 - mae: 0.1893 - val_loss: 0.0267 - val_mae: 0.1283\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0552 - mae: 0.1852 - val_loss: 0.0213 - val_mae: 0.1157\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0521 - mae: 0.1799 - val_loss: 0.0354 - val_mae: 0.1512\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 2s 105us/step - loss: 0.0546 - mae: 0.1834 - val_loss: 0.0239 - val_mae: 0.1207\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 2s 113us/step - loss: 0.0516 - mae: 0.1792 - val_loss: 0.0196 - val_mae: 0.1101\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0516 - mae: 0.1789 - val_loss: 0.0169 - val_mae: 0.1001\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0509 - mae: 0.1782 - val_loss: 0.0177 - val_mae: 0.1029\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0509 - mae: 0.1774 - val_loss: 0.0179 - val_mae: 0.1038\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0497 - mae: 0.1753 - val_loss: 0.0182 - val_mae: 0.1025\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0475 - mae: 0.1724 - val_loss: 0.0172 - val_mae: 0.1019\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0480 - mae: 0.1731 - val_loss: 0.0192 - val_mae: 0.1065\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0487 - mae: 0.1738 - val_loss: 0.0163 - val_mae: 0.0975\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0477 - mae: 0.1721 - val_loss: 0.0169 - val_mae: 0.1000\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0456 - mae: 0.1685 - val_loss: 0.0178 - val_mae: 0.1020\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0452 - mae: 0.1679 - val_loss: 0.0174 - val_mae: 0.1020\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0458 - mae: 0.1686 - val_loss: 0.0188 - val_mae: 0.1048\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0452 - mae: 0.1674 - val_loss: 0.0161 - val_mae: 0.0967\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0449 - mae: 0.1671 - val_loss: 0.0160 - val_mae: 0.0976\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0448 - mae: 0.1669 - val_loss: 0.0152 - val_mae: 0.0946\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0448 - mae: 0.1668 - val_loss: 0.0178 - val_mae: 0.1009\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0428 - mae: 0.1627 - val_loss: 0.0164 - val_mae: 0.0978\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0439 - mae: 0.1647 - val_loss: 0.0163 - val_mae: 0.0982\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0421 - mae: 0.1618 - val_loss: 0.0174 - val_mae: 0.1020\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0429 - mae: 0.1634 - val_loss: 0.0166 - val_mae: 0.0985\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0437 - mae: 0.1639 - val_loss: 0.0233 - val_mae: 0.1183\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0423 - mae: 0.1616 - val_loss: 0.0157 - val_mae: 0.0957\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0415 - mae: 0.1600 - val_loss: 0.0154 - val_mae: 0.0946\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0418 - mae: 0.1608 - val_loss: 0.0158 - val_mae: 0.0966\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0424 - mae: 0.1622 - val_loss: 0.0150 - val_mae: 0.0932\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0404 - mae: 0.1585 - val_loss: 0.0171 - val_mae: 0.1013\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0409 - mae: 0.1587 - val_loss: 0.0158 - val_mae: 0.0965\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0404 - mae: 0.1579 - val_loss: 0.0207 - val_mae: 0.1147\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0412 - mae: 0.1599 - val_loss: 0.0156 - val_mae: 0.0964\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0393 - mae: 0.1558 - val_loss: 0.0200 - val_mae: 0.1107\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0402 - mae: 0.1577 - val_loss: 0.0161 - val_mae: 0.0967\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0397 - mae: 0.1565 - val_loss: 0.0157 - val_mae: 0.0953\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0393 - mae: 0.1558 - val_loss: 0.0186 - val_mae: 0.1086\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 2s 121us/step - loss: 0.0386 - mae: 0.1550 - val_loss: 0.0157 - val_mae: 0.0952\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0387 - mae: 0.1548 - val_loss: 0.0183 - val_mae: 0.1033\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0398 - mae: 0.1565 - val_loss: 0.0157 - val_mae: 0.0953\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0380 - mae: 0.1544 - val_loss: 0.0180 - val_mae: 0.1040\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0384 - mae: 0.1546 - val_loss: 0.0158 - val_mae: 0.0965\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0381 - mae: 0.1540 - val_loss: 0.0148 - val_mae: 0.0928\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0378 - mae: 0.1527 - val_loss: 0.0164 - val_mae: 0.0977\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 2s 117us/step - loss: 0.0384 - mae: 0.1544 - val_loss: 0.0147 - val_mae: 0.0925\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0394 - mae: 0.1559 - val_loss: 0.0172 - val_mae: 0.1014\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0375 - mae: 0.1525 - val_loss: 0.0156 - val_mae: 0.0948\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0372 - mae: 0.1518 - val_loss: 0.0153 - val_mae: 0.0946\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0373 - mae: 0.1518 - val_loss: 0.0156 - val_mae: 0.0963\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0370 - mae: 0.1507 - val_loss: 0.0150 - val_mae: 0.0930\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0370 - mae: 0.1515 - val_loss: 0.0156 - val_mae: 0.0956\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0358 - mae: 0.1490 - val_loss: 0.0149 - val_mae: 0.0932\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0358 - mae: 0.1491 - val_loss: 0.0149 - val_mae: 0.0925\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0371 - mae: 0.1521 - val_loss: 0.0164 - val_mae: 0.0982\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0371 - mae: 0.1513 - val_loss: 0.0186 - val_mae: 0.1068\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0361 - mae: 0.1494 - val_loss: 0.0155 - val_mae: 0.0965\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0350 - mae: 0.1477 - val_loss: 0.0156 - val_mae: 0.0967\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 2s 119us/step - loss: 0.0349 - mae: 0.1474 - val_loss: 0.0149 - val_mae: 0.0930\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 2s 98us/step - loss: 0.0357 - mae: 0.1483 - val_loss: 0.0162 - val_mae: 0.0986\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0361 - mae: 0.1497 - val_loss: 0.0151 - val_mae: 0.0941\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0358 - mae: 0.1482 - val_loss: 0.0153 - val_mae: 0.0945\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0353 - mae: 0.1474 - val_loss: 0.0151 - val_mae: 0.0930\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0345 - mae: 0.1463 - val_loss: 0.0165 - val_mae: 0.0990\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0339 - mae: 0.1440 - val_loss: 0.0162 - val_mae: 0.0967\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0341 - mae: 0.1451 - val_loss: 0.0154 - val_mae: 0.0947\n",
      "Fold 3\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 2s 125us/step - loss: 2.8953 - mae: 1.2059 - val_loss: 0.7604 - val_mae: 0.6598\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.4171 - mae: 0.4842 - val_loss: 0.1277 - val_mae: 0.2675\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1607 - mae: 0.3124 - val_loss: 0.0508 - val_mae: 0.1680\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.1234 - mae: 0.2762 - val_loss: 0.0368 - val_mae: 0.1452\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1088 - mae: 0.2606 - val_loss: 0.0313 - val_mae: 0.1358\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0991 - mae: 0.2486 - val_loss: 0.0311 - val_mae: 0.1385\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0959 - mae: 0.2449 - val_loss: 0.0277 - val_mae: 0.1302\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0905 - mae: 0.2374 - val_loss: 0.0273 - val_mae: 0.1277\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 2s 113us/step - loss: 0.0859 - mae: 0.2312 - val_loss: 0.0237 - val_mae: 0.1202\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 2s 104us/step - loss: 0.0828 - mae: 0.2277 - val_loss: 0.0332 - val_mae: 0.1469\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0797 - mae: 0.2237 - val_loss: 0.0231 - val_mae: 0.1187\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0753 - mae: 0.2174 - val_loss: 0.0244 - val_mae: 0.1233\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0754 - mae: 0.2176 - val_loss: 0.0266 - val_mae: 0.1285\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0718 - mae: 0.2121 - val_loss: 0.0245 - val_mae: 0.1251\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0708 - mae: 0.2102 - val_loss: 0.0365 - val_mae: 0.1570\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0718 - mae: 0.2120 - val_loss: 0.0265 - val_mae: 0.1300\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0669 - mae: 0.2040 - val_loss: 0.0304 - val_mae: 0.1429\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0655 - mae: 0.2021 - val_loss: 0.0195 - val_mae: 0.1065\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0636 - mae: 0.1986 - val_loss: 0.0214 - val_mae: 0.1108\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0628 - mae: 0.1973 - val_loss: 0.0201 - val_mae: 0.1093\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0628 - mae: 0.1988 - val_loss: 0.0215 - val_mae: 0.1135\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0608 - mae: 0.1944 - val_loss: 0.0194 - val_mae: 0.1100\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0600 - mae: 0.1938 - val_loss: 0.0183 - val_mae: 0.1031\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0590 - mae: 0.1915 - val_loss: 0.0174 - val_mae: 0.1005\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0576 - mae: 0.1886 - val_loss: 0.0194 - val_mae: 0.1089\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0579 - mae: 0.1895 - val_loss: 0.0217 - val_mae: 0.1119\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0581 - mae: 0.1893 - val_loss: 0.0184 - val_mae: 0.1061\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0558 - mae: 0.1864 - val_loss: 0.0229 - val_mae: 0.1192\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0541 - mae: 0.1834 - val_loss: 0.0362 - val_mae: 0.1599\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0535 - mae: 0.1825 - val_loss: 0.0195 - val_mae: 0.1083\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0517 - mae: 0.1785 - val_loss: 0.0256 - val_mae: 0.1217\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0513 - mae: 0.1785 - val_loss: 0.0170 - val_mae: 0.1005\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0524 - mae: 0.1799 - val_loss: 0.0188 - val_mae: 0.1056\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0493 - mae: 0.1741 - val_loss: 0.0188 - val_mae: 0.1082\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0491 - mae: 0.1742 - val_loss: 0.0188 - val_mae: 0.1042\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0500 - mae: 0.1765 - val_loss: 0.0192 - val_mae: 0.1079\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0490 - mae: 0.1734 - val_loss: 0.0312 - val_mae: 0.1445\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0482 - mae: 0.1726 - val_loss: 0.0185 - val_mae: 0.1069\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0465 - mae: 0.1702 - val_loss: 0.0186 - val_mae: 0.1069\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0475 - mae: 0.1714 - val_loss: 0.0164 - val_mae: 0.0981\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0471 - mae: 0.1706 - val_loss: 0.0157 - val_mae: 0.0967\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0472 - mae: 0.1709 - val_loss: 0.0205 - val_mae: 0.1105\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0457 - mae: 0.1683 - val_loss: 0.0162 - val_mae: 0.0968\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0451 - mae: 0.1672 - val_loss: 0.0162 - val_mae: 0.0979\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0449 - mae: 0.1669 - val_loss: 0.0157 - val_mae: 0.0976\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0441 - mae: 0.1654 - val_loss: 0.0237 - val_mae: 0.1227\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0430 - mae: 0.1638 - val_loss: 0.0165 - val_mae: 0.0986\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0435 - mae: 0.1641 - val_loss: 0.0164 - val_mae: 0.1002\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0439 - mae: 0.1647 - val_loss: 0.0176 - val_mae: 0.1039\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0425 - mae: 0.1628 - val_loss: 0.0155 - val_mae: 0.0955\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0425 - mae: 0.1619 - val_loss: 0.0204 - val_mae: 0.1084\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0419 - mae: 0.1612 - val_loss: 0.0151 - val_mae: 0.0952\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0431 - mae: 0.1636 - val_loss: 0.0157 - val_mae: 0.0968\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0420 - mae: 0.1610 - val_loss: 0.0158 - val_mae: 0.0971\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0405 - mae: 0.1580 - val_loss: 0.0163 - val_mae: 0.0985\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0422 - mae: 0.1613 - val_loss: 0.0165 - val_mae: 0.0989\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0405 - mae: 0.1586 - val_loss: 0.0161 - val_mae: 0.0985\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0400 - mae: 0.1576 - val_loss: 0.0164 - val_mae: 0.0998\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0409 - mae: 0.1592 - val_loss: 0.0196 - val_mae: 0.1047\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0404 - mae: 0.1578 - val_loss: 0.0161 - val_mae: 0.0974\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0393 - mae: 0.1559 - val_loss: 0.0157 - val_mae: 0.0965\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0392 - mae: 0.1564 - val_loss: 0.0182 - val_mae: 0.1045\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0393 - mae: 0.1559 - val_loss: 0.0154 - val_mae: 0.0950\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0394 - mae: 0.1561 - val_loss: 0.0164 - val_mae: 0.0983\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0385 - mae: 0.1546 - val_loss: 0.0155 - val_mae: 0.0945\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0386 - mae: 0.1546 - val_loss: 0.0153 - val_mae: 0.0936\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0380 - mae: 0.1531 - val_loss: 0.0160 - val_mae: 0.0978\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.0386 - mae: 0.1549 - val_loss: 0.0153 - val_mae: 0.0960\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0381 - mae: 0.1531 - val_loss: 0.0156 - val_mae: 0.0953\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0380 - mae: 0.1536 - val_loss: 0.0146 - val_mae: 0.0924\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0374 - mae: 0.1524 - val_loss: 0.0152 - val_mae: 0.0933\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0369 - mae: 0.1511 - val_loss: 0.0159 - val_mae: 0.0979\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0374 - mae: 0.1523 - val_loss: 0.0160 - val_mae: 0.0958\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0366 - mae: 0.1510 - val_loss: 0.0158 - val_mae: 0.0948\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0376 - mae: 0.1523 - val_loss: 0.0145 - val_mae: 0.0914\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0366 - mae: 0.1500 - val_loss: 0.0158 - val_mae: 0.0944\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0366 - mae: 0.1507 - val_loss: 0.0158 - val_mae: 0.0972\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0360 - mae: 0.1496 - val_loss: 0.0167 - val_mae: 0.1003\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0358 - mae: 0.1486 - val_loss: 0.0171 - val_mae: 0.1026\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0360 - mae: 0.1492 - val_loss: 0.0188 - val_mae: 0.1065\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0356 - mae: 0.1485 - val_loss: 0.0156 - val_mae: 0.0964\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0358 - mae: 0.1486 - val_loss: 0.0196 - val_mae: 0.1091\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0361 - mae: 0.1494 - val_loss: 0.0162 - val_mae: 0.0975\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0335 - mae: 0.1435 - val_loss: 0.0155 - val_mae: 0.0957\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0349 - mae: 0.1462 - val_loss: 0.0156 - val_mae: 0.0937\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0340 - mae: 0.1448 - val_loss: 0.0165 - val_mae: 0.0999\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0340 - mae: 0.1449 - val_loss: 0.0175 - val_mae: 0.1006\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0347 - mae: 0.1461 - val_loss: 0.0149 - val_mae: 0.0920\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0340 - mae: 0.1448 - val_loss: 0.0144 - val_mae: 0.0922\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0341 - mae: 0.1449 - val_loss: 0.0147 - val_mae: 0.0932\n",
      "Epoch 91/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0336 - mae: 0.1438 - val_loss: 0.0156 - val_mae: 0.0954\n",
      "Epoch 92/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0340 - mae: 0.1445 - val_loss: 0.0148 - val_mae: 0.0939\n",
      "Epoch 93/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0338 - mae: 0.1446 - val_loss: 0.0148 - val_mae: 0.0930\n",
      "Epoch 94/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0338 - mae: 0.1444 - val_loss: 0.0150 - val_mae: 0.0935\n",
      "Epoch 95/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0330 - mae: 0.1428 - val_loss: 0.0146 - val_mae: 0.0923\n",
      "Epoch 96/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0318 - mae: 0.1399 - val_loss: 0.0152 - val_mae: 0.0956\n",
      "Epoch 97/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0334 - mae: 0.1429 - val_loss: 0.0146 - val_mae: 0.0919\n",
      "Epoch 98/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0332 - mae: 0.1425 - val_loss: 0.0149 - val_mae: 0.0937\n",
      "Epoch 99/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0323 - mae: 0.1411 - val_loss: 0.0150 - val_mae: 0.0949\n",
      "Epoch 100/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0330 - mae: 0.1424 - val_loss: 0.0148 - val_mae: 0.0922\n",
      "Fold 4\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 2s 122us/step - loss: 3.3174 - mae: 1.2794 - val_loss: 0.7508 - val_mae: 0.6628\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 47us/step - loss: 0.4777 - mae: 0.5184 - val_loss: 0.1256 - val_mae: 0.2632\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.1688 - mae: 0.3203 - val_loss: 0.0462 - val_mae: 0.1633\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.1305 - mae: 0.2851 - val_loss: 0.0448 - val_mae: 0.1611\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.1159 - mae: 0.2679 - val_loss: 0.0350 - val_mae: 0.1477\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.1048 - mae: 0.2551 - val_loss: 0.0262 - val_mae: 0.1243\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.1001 - mae: 0.2501 - val_loss: 0.0267 - val_mae: 0.1270\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0949 - mae: 0.2424 - val_loss: 0.0283 - val_mae: 0.1327\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0913 - mae: 0.2392 - val_loss: 0.0260 - val_mae: 0.1257\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0878 - mae: 0.2336 - val_loss: 0.0258 - val_mae: 0.1271\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0864 - mae: 0.2322 - val_loss: 0.0255 - val_mae: 0.1249\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0839 - mae: 0.2287 - val_loss: 0.0215 - val_mae: 0.1153\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0809 - mae: 0.2242 - val_loss: 0.0277 - val_mae: 0.1329\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0791 - mae: 0.2217 - val_loss: 0.0294 - val_mae: 0.1376\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0779 - mae: 0.2202 - val_loss: 0.0226 - val_mae: 0.1161\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0765 - mae: 0.2184 - val_loss: 0.0210 - val_mae: 0.1125\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0762 - mae: 0.2179 - val_loss: 0.0234 - val_mae: 0.1213\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0742 - mae: 0.2156 - val_loss: 0.0224 - val_mae: 0.1151\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0745 - mae: 0.2155 - val_loss: 0.0238 - val_mae: 0.1213\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0699 - mae: 0.2090 - val_loss: 0.0213 - val_mae: 0.1114\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0687 - mae: 0.2077 - val_loss: 0.0185 - val_mae: 0.1046\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0676 - mae: 0.2053 - val_loss: 0.0218 - val_mae: 0.1151\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0663 - mae: 0.2035 - val_loss: 0.0184 - val_mae: 0.1053\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0671 - mae: 0.2040 - val_loss: 0.0201 - val_mae: 0.1107\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0666 - mae: 0.2037 - val_loss: 0.0242 - val_mae: 0.1231\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0642 - mae: 0.2000 - val_loss: 0.0244 - val_mae: 0.1234\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0646 - mae: 0.1997 - val_loss: 0.0258 - val_mae: 0.1323\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0634 - mae: 0.1988 - val_loss: 0.0182 - val_mae: 0.1037\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0618 - mae: 0.1950 - val_loss: 0.0198 - val_mae: 0.1065\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0597 - mae: 0.1930 - val_loss: 0.0196 - val_mae: 0.1061\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0587 - mae: 0.1899 - val_loss: 0.0197 - val_mae: 0.1097\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0595 - mae: 0.1926 - val_loss: 0.0207 - val_mae: 0.1134\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0581 - mae: 0.1898 - val_loss: 0.0184 - val_mae: 0.1038\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0571 - mae: 0.1882 - val_loss: 0.0254 - val_mae: 0.1275\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0583 - mae: 0.1899 - val_loss: 0.0253 - val_mae: 0.1281\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0546 - mae: 0.1843 - val_loss: 0.0169 - val_mae: 0.1001\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0536 - mae: 0.1835 - val_loss: 0.0306 - val_mae: 0.1455\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0530 - mae: 0.1818 - val_loss: 0.0185 - val_mae: 0.1065\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0532 - mae: 0.1819 - val_loss: 0.0178 - val_mae: 0.1037\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0505 - mae: 0.1775 - val_loss: 0.0170 - val_mae: 0.0990\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0526 - mae: 0.1812 - val_loss: 0.0216 - val_mae: 0.1160\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.0505 - mae: 0.1771 - val_loss: 0.0161 - val_mae: 0.0971\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0516 - mae: 0.1794 - val_loss: 0.0177 - val_mae: 0.1000\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0512 - mae: 0.1777 - val_loss: 0.0163 - val_mae: 0.0977\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0486 - mae: 0.1738 - val_loss: 0.0184 - val_mae: 0.1059\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0493 - mae: 0.1747 - val_loss: 0.0218 - val_mae: 0.1133\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0494 - mae: 0.1755 - val_loss: 0.0169 - val_mae: 0.0988\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0486 - mae: 0.1739 - val_loss: 0.0188 - val_mae: 0.1041\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0504 - mae: 0.1774 - val_loss: 0.0184 - val_mae: 0.1067\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0474 - mae: 0.1715 - val_loss: 0.0282 - val_mae: 0.1357\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0488 - mae: 0.1732 - val_loss: 0.0165 - val_mae: 0.0995\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0462 - mae: 0.1695 - val_loss: 0.0162 - val_mae: 0.0979\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0468 - mae: 0.1699 - val_loss: 0.0156 - val_mae: 0.0953\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0458 - mae: 0.1682 - val_loss: 0.0158 - val_mae: 0.0959\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0457 - mae: 0.1688 - val_loss: 0.0210 - val_mae: 0.1133\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0456 - mae: 0.1685 - val_loss: 0.0183 - val_mae: 0.1032\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0449 - mae: 0.1674 - val_loss: 0.0159 - val_mae: 0.0959\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0441 - mae: 0.1654 - val_loss: 0.0161 - val_mae: 0.0979\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0443 - mae: 0.1653 - val_loss: 0.0206 - val_mae: 0.1101\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0443 - mae: 0.1653 - val_loss: 0.0175 - val_mae: 0.1024\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0433 - mae: 0.1638 - val_loss: 0.0162 - val_mae: 0.0973\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0430 - mae: 0.1629 - val_loss: 0.0184 - val_mae: 0.1055\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0441 - mae: 0.1652 - val_loss: 0.0175 - val_mae: 0.1035\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0417 - mae: 0.1609 - val_loss: 0.0152 - val_mae: 0.0940\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0421 - mae: 0.1611 - val_loss: 0.0151 - val_mae: 0.0939\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0420 - mae: 0.1616 - val_loss: 0.0156 - val_mae: 0.0975\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0419 - mae: 0.1616 - val_loss: 0.0185 - val_mae: 0.1060\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0424 - mae: 0.1619 - val_loss: 0.0150 - val_mae: 0.0934\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0408 - mae: 0.1593 - val_loss: 0.0169 - val_mae: 0.1024\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0418 - mae: 0.1609 - val_loss: 0.0163 - val_mae: 0.0964\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0404 - mae: 0.1585 - val_loss: 0.0163 - val_mae: 0.0990\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0405 - mae: 0.1584 - val_loss: 0.0155 - val_mae: 0.0953\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0402 - mae: 0.1578 - val_loss: 0.0165 - val_mae: 0.0989\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0407 - mae: 0.1588 - val_loss: 0.0182 - val_mae: 0.1047\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0405 - mae: 0.1583 - val_loss: 0.0160 - val_mae: 0.0966\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0399 - mae: 0.1572 - val_loss: 0.0183 - val_mae: 0.1068\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0395 - mae: 0.1559 - val_loss: 0.0155 - val_mae: 0.0953\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0395 - mae: 0.1563 - val_loss: 0.0159 - val_mae: 0.0977\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0388 - mae: 0.1544 - val_loss: 0.0186 - val_mae: 0.1076\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0386 - mae: 0.1550 - val_loss: 0.0160 - val_mae: 0.0971\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0380 - mae: 0.1532 - val_loss: 0.0153 - val_mae: 0.0955\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0379 - mae: 0.1532 - val_loss: 0.0200 - val_mae: 0.1130\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0382 - mae: 0.1534 - val_loss: 0.0151 - val_mae: 0.0953\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0376 - mae: 0.1520 - val_loss: 0.0181 - val_mae: 0.1034\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0379 - mae: 0.1534 - val_loss: 0.0156 - val_mae: 0.0946\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0370 - mae: 0.1514 - val_loss: 0.0178 - val_mae: 0.1029\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0376 - mae: 0.1528 - val_loss: 0.0152 - val_mae: 0.0938\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0366 - mae: 0.1509 - val_loss: 0.0167 - val_mae: 0.1006\n",
      "Fold 5\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 3s 141us/step - loss: 3.1536 - mae: 1.2516 - val_loss: 0.7619 - val_mae: 0.6729\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.4715 - mae: 0.5145 - val_loss: 0.1249 - val_mae: 0.2720\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.1720 - mae: 0.3216 - val_loss: 0.0568 - val_mae: 0.1852\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1336 - mae: 0.2864 - val_loss: 0.0407 - val_mae: 0.1577\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1127 - mae: 0.2639 - val_loss: 0.0301 - val_mae: 0.1344\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1031 - mae: 0.2530 - val_loss: 0.0356 - val_mae: 0.1505\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0961 - mae: 0.2447 - val_loss: 0.0246 - val_mae: 0.1224\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0932 - mae: 0.2410 - val_loss: 0.0231 - val_mae: 0.1183\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0884 - mae: 0.2339 - val_loss: 0.0233 - val_mae: 0.1199\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0835 - mae: 0.2279 - val_loss: 0.0257 - val_mae: 0.1248\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0841 - mae: 0.2293 - val_loss: 0.0276 - val_mae: 0.1322\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0810 - mae: 0.2246 - val_loss: 0.0217 - val_mae: 0.1140\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0783 - mae: 0.2208 - val_loss: 0.0287 - val_mae: 0.1360\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0757 - mae: 0.2177 - val_loss: 0.0223 - val_mae: 0.1160\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0748 - mae: 0.2158 - val_loss: 0.0258 - val_mae: 0.1262\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0739 - mae: 0.2146 - val_loss: 0.0249 - val_mae: 0.1253\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0704 - mae: 0.2088 - val_loss: 0.0258 - val_mae: 0.1255\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0694 - mae: 0.2075 - val_loss: 0.0315 - val_mae: 0.1407\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - ETA: 0s - loss: 0.0671 - mae: 0.204 - 1s 66us/step - loss: 0.0670 - mae: 0.2042 - val_loss: 0.0225 - val_mae: 0.1183\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0679 - mae: 0.2058 - val_loss: 0.0327 - val_mae: 0.1471\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0677 - mae: 0.2064 - val_loss: 0.0226 - val_mae: 0.1180\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0634 - mae: 0.1987 - val_loss: 0.0209 - val_mae: 0.1115\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0662 - mae: 0.2033 - val_loss: 0.0302 - val_mae: 0.1373\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0655 - mae: 0.2016 - val_loss: 0.0211 - val_mae: 0.1130\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0605 - mae: 0.1940 - val_loss: 0.0189 - val_mae: 0.1056\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0601 - mae: 0.1934 - val_loss: 0.0202 - val_mae: 0.1107\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0583 - mae: 0.1913 - val_loss: 0.0229 - val_mae: 0.1193\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0580 - mae: 0.1896 - val_loss: 0.0190 - val_mae: 0.1065\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0586 - mae: 0.1907 - val_loss: 0.0197 - val_mae: 0.1092\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0550 - mae: 0.1846 - val_loss: 0.0187 - val_mae: 0.1046\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0553 - mae: 0.1846 - val_loss: 0.0256 - val_mae: 0.1276\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0543 - mae: 0.1840 - val_loss: 0.0166 - val_mae: 0.0994\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0538 - mae: 0.1823 - val_loss: 0.0175 - val_mae: 0.1022\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0523 - mae: 0.1800 - val_loss: 0.0162 - val_mae: 0.0968\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0514 - mae: 0.1783 - val_loss: 0.0180 - val_mae: 0.1031\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0522 - mae: 0.1800 - val_loss: 0.0171 - val_mae: 0.1009\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0505 - mae: 0.1774 - val_loss: 0.0171 - val_mae: 0.1003\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0514 - mae: 0.1790 - val_loss: 0.0167 - val_mae: 0.0986\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0494 - mae: 0.1754 - val_loss: 0.0170 - val_mae: 0.0996\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0498 - mae: 0.1758 - val_loss: 0.0231 - val_mae: 0.1198\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0483 - mae: 0.1736 - val_loss: 0.0162 - val_mae: 0.0970\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0490 - mae: 0.1741 - val_loss: 0.0170 - val_mae: 0.0986\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0482 - mae: 0.1727 - val_loss: 0.0173 - val_mae: 0.1014\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0467 - mae: 0.1699 - val_loss: 0.0190 - val_mae: 0.1066\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0462 - mae: 0.1698 - val_loss: 0.0162 - val_mae: 0.0979\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0459 - mae: 0.1679 - val_loss: 0.0173 - val_mae: 0.1001\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0445 - mae: 0.1663 - val_loss: 0.0158 - val_mae: 0.0952\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0461 - mae: 0.1695 - val_loss: 0.0178 - val_mae: 0.1025\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0447 - mae: 0.1668 - val_loss: 0.0207 - val_mae: 0.1103\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0454 - mae: 0.1678 - val_loss: 0.0171 - val_mae: 0.0999\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0434 - mae: 0.1639 - val_loss: 0.0161 - val_mae: 0.0959\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0435 - mae: 0.1643 - val_loss: 0.0159 - val_mae: 0.0957\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0438 - mae: 0.1644 - val_loss: 0.0172 - val_mae: 0.0993\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0430 - mae: 0.1627 - val_loss: 0.0185 - val_mae: 0.1031\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0436 - mae: 0.1643 - val_loss: 0.0167 - val_mae: 0.0972\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0429 - mae: 0.1631 - val_loss: 0.0200 - val_mae: 0.1078\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0420 - mae: 0.1612 - val_loss: 0.0185 - val_mae: 0.1048\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0426 - mae: 0.1631 - val_loss: 0.0165 - val_mae: 0.0971\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0427 - mae: 0.1630 - val_loss: 0.0165 - val_mae: 0.0975\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0422 - mae: 0.1616 - val_loss: 0.0163 - val_mae: 0.0990\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0411 - mae: 0.1595 - val_loss: 0.0163 - val_mae: 0.0975\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0412 - mae: 0.1595 - val_loss: 0.0181 - val_mae: 0.1026\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0420 - mae: 0.1618 - val_loss: 0.0192 - val_mae: 0.1092\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0405 - mae: 0.1585 - val_loss: 0.0185 - val_mae: 0.1053\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0403 - mae: 0.1584 - val_loss: 0.0156 - val_mae: 0.0952\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0416 - mae: 0.1606 - val_loss: 0.0166 - val_mae: 0.0988\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0405 - mae: 0.1583 - val_loss: 0.0159 - val_mae: 0.0950\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0409 - mae: 0.1595 - val_loss: 0.0192 - val_mae: 0.1048\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0405 - mae: 0.1582 - val_loss: 0.0172 - val_mae: 0.1009\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0390 - mae: 0.1554 - val_loss: 0.0155 - val_mae: 0.0939\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0393 - mae: 0.1561 - val_loss: 0.0160 - val_mae: 0.0962\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0392 - mae: 0.1562 - val_loss: 0.0205 - val_mae: 0.1116\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0386 - mae: 0.1551 - val_loss: 0.0158 - val_mae: 0.0954\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0385 - mae: 0.1546 - val_loss: 0.0161 - val_mae: 0.0961\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0385 - mae: 0.1543 - val_loss: 0.0164 - val_mae: 0.0967\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0381 - mae: 0.1536 - val_loss: 0.0168 - val_mae: 0.0979\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0387 - mae: 0.1548 - val_loss: 0.0151 - val_mae: 0.0930\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0376 - mae: 0.1526 - val_loss: 0.0162 - val_mae: 0.0970\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0371 - mae: 0.1512 - val_loss: 0.0159 - val_mae: 0.0956\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0372 - mae: 0.1518 - val_loss: 0.0169 - val_mae: 0.0983\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0371 - mae: 0.1515 - val_loss: 0.0156 - val_mae: 0.0944\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0373 - mae: 0.1519 - val_loss: 0.0176 - val_mae: 0.1011\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0360 - mae: 0.1494 - val_loss: 0.0163 - val_mae: 0.0971\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0362 - mae: 0.1504 - val_loss: 0.0162 - val_mae: 0.0971\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0364 - mae: 0.1495 - val_loss: 0.0160 - val_mae: 0.0956\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0363 - mae: 0.1501 - val_loss: 0.0152 - val_mae: 0.0937\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0354 - mae: 0.1475 - val_loss: 0.0174 - val_mae: 0.1001\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0356 - mae: 0.1486 - val_loss: 0.0156 - val_mae: 0.0941\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0355 - mae: 0.1486 - val_loss: 0.0155 - val_mae: 0.0945\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0348 - mae: 0.1466 - val_loss: 0.0157 - val_mae: 0.0955\n",
      "Epoch 91/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0353 - mae: 0.1480 - val_loss: 0.0156 - val_mae: 0.0951\n",
      "Epoch 92/100\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0343 - mae: 0.1453 - val_loss: 0.0169 - val_mae: 0.0994\n",
      "Epoch 93/100\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0348 - mae: 0.1467 - val_loss: 0.0160 - val_mae: 0.0970\n",
      "Epoch 94/100\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0344 - mae: 0.1458 - val_loss: 0.0164 - val_mae: 0.0975\n",
      "Epoch 95/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0343 - mae: 0.1457 - val_loss: 0.0157 - val_mae: 0.0948\n",
      "Epoch 96/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0347 - mae: 0.1460 - val_loss: 0.0158 - val_mae: 0.0960\n",
      "Epoch 97/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0345 - mae: 0.1457 - val_loss: 0.0164 - val_mae: 0.0967\n",
      "Fold 6\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 2s 129us/step - loss: 2.8700 - mae: 1.1971 - val_loss: 0.6564 - val_mae: 0.6093\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.4110 - mae: 0.4803 - val_loss: 0.1075 - val_mae: 0.2411\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.1658 - mae: 0.3186 - val_loss: 0.0514 - val_mae: 0.1680\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.1269 - mae: 0.2796 - val_loss: 0.0381 - val_mae: 0.1455\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.1099 - mae: 0.2607 - val_loss: 0.0386 - val_mae: 0.1532\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1003 - mae: 0.2494 - val_loss: 0.0288 - val_mae: 0.1292\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0921 - mae: 0.2392 - val_loss: 0.0291 - val_mae: 0.1325\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0866 - mae: 0.2333 - val_loss: 0.0271 - val_mae: 0.1284\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0843 - mae: 0.2293 - val_loss: 0.0269 - val_mae: 0.1278\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0795 - mae: 0.2225 - val_loss: 0.0242 - val_mae: 0.1200\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0760 - mae: 0.2179 - val_loss: 0.0261 - val_mae: 0.1234\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0737 - mae: 0.2145 - val_loss: 0.0227 - val_mae: 0.1167\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0734 - mae: 0.2141 - val_loss: 0.0228 - val_mae: 0.1171\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0722 - mae: 0.2130 - val_loss: 0.0282 - val_mae: 0.1337\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0704 - mae: 0.2092 - val_loss: 0.0240 - val_mae: 0.1225\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0668 - mae: 0.2040 - val_loss: 0.0225 - val_mae: 0.1182\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0645 - mae: 0.2007 - val_loss: 0.0286 - val_mae: 0.1360\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0649 - mae: 0.2007 - val_loss: 0.0201 - val_mae: 0.1093\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0619 - mae: 0.1958 - val_loss: 0.0193 - val_mae: 0.1068\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0599 - mae: 0.1927 - val_loss: 0.0209 - val_mae: 0.1130\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0589 - mae: 0.1910 - val_loss: 0.0190 - val_mae: 0.1086\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0582 - mae: 0.1903 - val_loss: 0.0260 - val_mae: 0.1313\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0601 - mae: 0.1932 - val_loss: 0.0222 - val_mae: 0.1166\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0557 - mae: 0.1866 - val_loss: 0.0180 - val_mae: 0.1032\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0558 - mae: 0.1859 - val_loss: 0.0190 - val_mae: 0.1065\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0534 - mae: 0.1822 - val_loss: 0.0219 - val_mae: 0.1123\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0537 - mae: 0.1822 - val_loss: 0.0170 - val_mae: 0.1010\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0529 - mae: 0.1811 - val_loss: 0.0180 - val_mae: 0.1043\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0511 - mae: 0.1786 - val_loss: 0.0206 - val_mae: 0.1109\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0494 - mae: 0.1752 - val_loss: 0.0201 - val_mae: 0.1118\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0510 - mae: 0.1783 - val_loss: 0.0193 - val_mae: 0.1075\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0507 - mae: 0.1774 - val_loss: 0.0175 - val_mae: 0.1018\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0487 - mae: 0.1735 - val_loss: 0.0185 - val_mae: 0.1046\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0480 - mae: 0.1721 - val_loss: 0.0198 - val_mae: 0.1071\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0477 - mae: 0.1715 - val_loss: 0.0183 - val_mae: 0.1052\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0460 - mae: 0.1686 - val_loss: 0.0240 - val_mae: 0.1232\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0454 - mae: 0.1678 - val_loss: 0.0182 - val_mae: 0.1066\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0463 - mae: 0.1690 - val_loss: 0.0181 - val_mae: 0.1047\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0453 - mae: 0.1677 - val_loss: 0.0188 - val_mae: 0.1058\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0455 - mae: 0.1681 - val_loss: 0.0165 - val_mae: 0.0987\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0446 - mae: 0.1667 - val_loss: 0.0170 - val_mae: 0.1001\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0450 - mae: 0.1666 - val_loss: 0.0183 - val_mae: 0.1037\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0447 - mae: 0.1657 - val_loss: 0.0183 - val_mae: 0.1027\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0422 - mae: 0.1619 - val_loss: 0.0176 - val_mae: 0.1024\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0437 - mae: 0.1638 - val_loss: 0.0165 - val_mae: 0.0995\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0422 - mae: 0.1620 - val_loss: 0.0168 - val_mae: 0.1011\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0424 - mae: 0.1624 - val_loss: 0.0170 - val_mae: 0.1007\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0429 - mae: 0.1630 - val_loss: 0.0164 - val_mae: 0.0980\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0418 - mae: 0.1610 - val_loss: 0.0213 - val_mae: 0.1142\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0419 - mae: 0.1617 - val_loss: 0.0166 - val_mae: 0.0989\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0406 - mae: 0.1585 - val_loss: 0.0165 - val_mae: 0.0972\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0429 - mae: 0.1630 - val_loss: 0.0180 - val_mae: 0.1027\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0411 - mae: 0.1594 - val_loss: 0.0156 - val_mae: 0.0954\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0399 - mae: 0.1566 - val_loss: 0.0157 - val_mae: 0.0947\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0401 - mae: 0.1576 - val_loss: 0.0155 - val_mae: 0.0956\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0401 - mae: 0.1577 - val_loss: 0.0157 - val_mae: 0.0964\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0402 - mae: 0.1572 - val_loss: 0.0173 - val_mae: 0.1008\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0402 - mae: 0.1579 - val_loss: 0.0158 - val_mae: 0.0956\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0388 - mae: 0.1552 - val_loss: 0.0160 - val_mae: 0.0963\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0384 - mae: 0.1543 - val_loss: 0.0163 - val_mae: 0.0975\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0391 - mae: 0.1547 - val_loss: 0.0162 - val_mae: 0.0978\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0399 - mae: 0.1565 - val_loss: 0.0161 - val_mae: 0.0982\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0380 - mae: 0.1539 - val_loss: 0.0169 - val_mae: 0.1001\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0392 - mae: 0.1555 - val_loss: 0.0231 - val_mae: 0.1182\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0393 - mae: 0.1560 - val_loss: 0.0158 - val_mae: 0.0980\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.0376 - mae: 0.1526 - val_loss: 0.0149 - val_mae: 0.0924\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0372 - mae: 0.1515 - val_loss: 0.0161 - val_mae: 0.0973\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0365 - mae: 0.1504 - val_loss: 0.0162 - val_mae: 0.0977\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0375 - mae: 0.1522 - val_loss: 0.0156 - val_mae: 0.0950\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0375 - mae: 0.1527 - val_loss: 0.0158 - val_mae: 0.0968\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0367 - mae: 0.1503 - val_loss: 0.0163 - val_mae: 0.0977\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0367 - mae: 0.1506 - val_loss: 0.0157 - val_mae: 0.0965\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0366 - mae: 0.1508 - val_loss: 0.0150 - val_mae: 0.0930\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0355 - mae: 0.1480 - val_loss: 0.0161 - val_mae: 0.0974\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0365 - mae: 0.1500 - val_loss: 0.0153 - val_mae: 0.0945\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0364 - mae: 0.1504 - val_loss: 0.0162 - val_mae: 0.0981\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0360 - mae: 0.1494 - val_loss: 0.0162 - val_mae: 0.0962\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0355 - mae: 0.1481 - val_loss: 0.0165 - val_mae: 0.1003\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0358 - mae: 0.1488 - val_loss: 0.0158 - val_mae: 0.0970\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0354 - mae: 0.1478 - val_loss: 0.0171 - val_mae: 0.0998\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0351 - mae: 0.1471 - val_loss: 0.0156 - val_mae: 0.0955\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0346 - mae: 0.1462 - val_loss: 0.0158 - val_mae: 0.0959\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0351 - mae: 0.1471 - val_loss: 0.0158 - val_mae: 0.0945\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0347 - mae: 0.1466 - val_loss: 0.0154 - val_mae: 0.0944\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0347 - mae: 0.1462 - val_loss: 0.0172 - val_mae: 0.0993\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0346 - mae: 0.1462 - val_loss: 0.0164 - val_mae: 0.0986\n",
      "Fold 7\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 3s 136us/step - loss: 3.1624 - mae: 1.2496 - val_loss: 0.7307 - val_mae: 0.6424\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.4578 - mae: 0.5051 - val_loss: 0.1061 - val_mae: 0.2422\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.1623 - mae: 0.3143 - val_loss: 0.0533 - val_mae: 0.1749\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1263 - mae: 0.2795 - val_loss: 0.0341 - val_mae: 0.1397\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1145 - mae: 0.2668 - val_loss: 0.0306 - val_mae: 0.1327\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1028 - mae: 0.2518 - val_loss: 0.0287 - val_mae: 0.1303\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0975 - mae: 0.2459 - val_loss: 0.0306 - val_mae: 0.1342\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0891 - mae: 0.2361 - val_loss: 0.0269 - val_mae: 0.1242\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0870 - mae: 0.2316 - val_loss: 0.0242 - val_mae: 0.1182\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0869 - mae: 0.2330 - val_loss: 0.0255 - val_mae: 0.1223\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0818 - mae: 0.2260 - val_loss: 0.0343 - val_mae: 0.1480\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0773 - mae: 0.2197 - val_loss: 0.0247 - val_mae: 0.1232\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0759 - mae: 0.2175 - val_loss: 0.0261 - val_mae: 0.1286\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0744 - mae: 0.2150 - val_loss: 0.0215 - val_mae: 0.1123\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0725 - mae: 0.2115 - val_loss: 0.0278 - val_mae: 0.1329\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0687 - mae: 0.2075 - val_loss: 0.0242 - val_mae: 0.1235\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0679 - mae: 0.2053 - val_loss: 0.0266 - val_mae: 0.1289\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0660 - mae: 0.2026 - val_loss: 0.0214 - val_mae: 0.1143\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0670 - mae: 0.2039 - val_loss: 0.0289 - val_mae: 0.1370\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0676 - mae: 0.2052 - val_loss: 0.0208 - val_mae: 0.1120\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0640 - mae: 0.1998 - val_loss: 0.0256 - val_mae: 0.1253\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0648 - mae: 0.2014 - val_loss: 0.0228 - val_mae: 0.1160\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0631 - mae: 0.1979 - val_loss: 0.0283 - val_mae: 0.1355\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0600 - mae: 0.1929 - val_loss: 0.0249 - val_mae: 0.1225\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0590 - mae: 0.1916 - val_loss: 0.0200 - val_mae: 0.1096\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0590 - mae: 0.1912 - val_loss: 0.0188 - val_mae: 0.1049\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0557 - mae: 0.1863 - val_loss: 0.0219 - val_mae: 0.1177\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0560 - mae: 0.1866 - val_loss: 0.0241 - val_mae: 0.1216\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0550 - mae: 0.1843 - val_loss: 0.0214 - val_mae: 0.1143\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0549 - mae: 0.1844 - val_loss: 0.0187 - val_mae: 0.1048\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0529 - mae: 0.1811 - val_loss: 0.0186 - val_mae: 0.1052\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0513 - mae: 0.1789 - val_loss: 0.0184 - val_mae: 0.1035\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0509 - mae: 0.1777 - val_loss: 0.0192 - val_mae: 0.1072\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0504 - mae: 0.1761 - val_loss: 0.0211 - val_mae: 0.1117\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0513 - mae: 0.1786 - val_loss: 0.0185 - val_mae: 0.1053\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0491 - mae: 0.1747 - val_loss: 0.0187 - val_mae: 0.1046\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0499 - mae: 0.1765 - val_loss: 0.0192 - val_mae: 0.1064\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0511 - mae: 0.1783 - val_loss: 0.0192 - val_mae: 0.1081\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0474 - mae: 0.1717 - val_loss: 0.0178 - val_mae: 0.1015\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0468 - mae: 0.1709 - val_loss: 0.0175 - val_mae: 0.1014\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0463 - mae: 0.1692 - val_loss: 0.0223 - val_mae: 0.1167\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0466 - mae: 0.1700 - val_loss: 0.0200 - val_mae: 0.1083\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0456 - mae: 0.1681 - val_loss: 0.0175 - val_mae: 0.1009\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0469 - mae: 0.1706 - val_loss: 0.0211 - val_mae: 0.1131\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0468 - mae: 0.1694 - val_loss: 0.0202 - val_mae: 0.1092\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0456 - mae: 0.1684 - val_loss: 0.0196 - val_mae: 0.1098\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0451 - mae: 0.1670 - val_loss: 0.0226 - val_mae: 0.1163\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0456 - mae: 0.1681 - val_loss: 0.0188 - val_mae: 0.1047\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0435 - mae: 0.1648 - val_loss: 0.0181 - val_mae: 0.1028\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0435 - mae: 0.1641 - val_loss: 0.0193 - val_mae: 0.1059\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0430 - mae: 0.1639 - val_loss: 0.0187 - val_mae: 0.1046\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0443 - mae: 0.1655 - val_loss: 0.0227 - val_mae: 0.1179\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0440 - mae: 0.1656 - val_loss: 0.0185 - val_mae: 0.1057\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0427 - mae: 0.1628 - val_loss: 0.0221 - val_mae: 0.1153\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0431 - mae: 0.1641 - val_loss: 0.0164 - val_mae: 0.0971\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0424 - mae: 0.1622 - val_loss: 0.0176 - val_mae: 0.1023\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0419 - mae: 0.1610 - val_loss: 0.0186 - val_mae: 0.1055\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0424 - mae: 0.1626 - val_loss: 0.0197 - val_mae: 0.1101\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0412 - mae: 0.1607 - val_loss: 0.0185 - val_mae: 0.1051\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0411 - mae: 0.1594 - val_loss: 0.0178 - val_mae: 0.1026\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0408 - mae: 0.1597 - val_loss: 0.0177 - val_mae: 0.1021\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0408 - mae: 0.1587 - val_loss: 0.0171 - val_mae: 0.0998\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0405 - mae: 0.1584 - val_loss: 0.0209 - val_mae: 0.1084\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0407 - mae: 0.1587 - val_loss: 0.0165 - val_mae: 0.0981\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0418 - mae: 0.1606 - val_loss: 0.0170 - val_mae: 0.0985\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0396 - mae: 0.1566 - val_loss: 0.0174 - val_mae: 0.1006\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0398 - mae: 0.1572 - val_loss: 0.0183 - val_mae: 0.1033\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0392 - mae: 0.1561 - val_loss: 0.0190 - val_mae: 0.1071\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0389 - mae: 0.1554 - val_loss: 0.0192 - val_mae: 0.1065\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0389 - mae: 0.1547 - val_loss: 0.0174 - val_mae: 0.1002\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0389 - mae: 0.1550 - val_loss: 0.0173 - val_mae: 0.1001\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0390 - mae: 0.1548 - val_loss: 0.0193 - val_mae: 0.1068\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0390 - mae: 0.1553 - val_loss: 0.0182 - val_mae: 0.1031\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0378 - mae: 0.1527 - val_loss: 0.0181 - val_mae: 0.1036\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0371 - mae: 0.1513 - val_loss: 0.0182 - val_mae: 0.1030\n",
      "Fold 8\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 3s 179us/step - loss: 3.1603 - mae: 1.2522 - val_loss: 0.7232 - val_mae: 0.6419\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.4493 - mae: 0.4993 - val_loss: 0.1103 - val_mae: 0.2481\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.1743 - mae: 0.3256 - val_loss: 0.0474 - val_mae: 0.1631\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.1364 - mae: 0.2909 - val_loss: 0.0381 - val_mae: 0.1462\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.1198 - mae: 0.2735 - val_loss: 0.0432 - val_mae: 0.1629\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1082 - mae: 0.2598 - val_loss: 0.0336 - val_mae: 0.1424\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0977 - mae: 0.2477 - val_loss: 0.0273 - val_mae: 0.1276\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0937 - mae: 0.2411 - val_loss: 0.0267 - val_mae: 0.1252\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0903 - mae: 0.2382 - val_loss: 0.0265 - val_mae: 0.1255\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0860 - mae: 0.2326 - val_loss: 0.0232 - val_mae: 0.1161\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0817 - mae: 0.2265 - val_loss: 0.0263 - val_mae: 0.1270\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0825 - mae: 0.2271 - val_loss: 0.0248 - val_mae: 0.1209\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0780 - mae: 0.2203 - val_loss: 0.0241 - val_mae: 0.1178\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0748 - mae: 0.2160 - val_loss: 0.0230 - val_mae: 0.1201\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0744 - mae: 0.2155 - val_loss: 0.0292 - val_mae: 0.1350\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0753 - mae: 0.2169 - val_loss: 0.0283 - val_mae: 0.1326\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 2s 118us/step - loss: 0.0700 - mae: 0.2086 - val_loss: 0.0224 - val_mae: 0.1124\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0692 - mae: 0.2079 - val_loss: 0.0212 - val_mae: 0.1115\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0673 - mae: 0.2053 - val_loss: 0.0240 - val_mae: 0.1225\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0678 - mae: 0.2068 - val_loss: 0.0200 - val_mae: 0.1069\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0644 - mae: 0.2010 - val_loss: 0.0196 - val_mae: 0.1073\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0646 - mae: 0.2004 - val_loss: 0.0259 - val_mae: 0.1296\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0619 - mae: 0.1967 - val_loss: 0.0193 - val_mae: 0.1074\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0609 - mae: 0.1953 - val_loss: 0.0198 - val_mae: 0.1073\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0597 - mae: 0.1931 - val_loss: 0.0185 - val_mae: 0.1035\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0592 - mae: 0.1931 - val_loss: 0.0184 - val_mae: 0.1030\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0589 - mae: 0.1914 - val_loss: 0.0193 - val_mae: 0.1063\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0575 - mae: 0.1891 - val_loss: 0.0182 - val_mae: 0.1037\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0563 - mae: 0.1873 - val_loss: 0.0187 - val_mae: 0.1047\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0542 - mae: 0.1836 - val_loss: 0.0184 - val_mae: 0.1048\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0557 - mae: 0.1860 - val_loss: 0.0207 - val_mae: 0.1136\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0540 - mae: 0.1832 - val_loss: 0.0186 - val_mae: 0.1031\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0533 - mae: 0.1823 - val_loss: 0.0195 - val_mae: 0.1075\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0516 - mae: 0.1798 - val_loss: 0.0189 - val_mae: 0.1061\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0499 - mae: 0.1760 - val_loss: 0.0185 - val_mae: 0.1054\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0524 - mae: 0.1806 - val_loss: 0.0173 - val_mae: 0.1011\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0503 - mae: 0.1771 - val_loss: 0.0200 - val_mae: 0.1094\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0509 - mae: 0.1777 - val_loss: 0.0170 - val_mae: 0.0992\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0497 - mae: 0.1756 - val_loss: 0.0214 - val_mae: 0.1146\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0491 - mae: 0.1748 - val_loss: 0.0199 - val_mae: 0.1082\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0483 - mae: 0.1730 - val_loss: 0.0191 - val_mae: 0.1074\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0468 - mae: 0.1706 - val_loss: 0.0189 - val_mae: 0.1053\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0491 - mae: 0.1744 - val_loss: 0.0184 - val_mae: 0.1042\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0474 - mae: 0.1715 - val_loss: 0.0164 - val_mae: 0.0975\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0468 - mae: 0.1709 - val_loss: 0.0177 - val_mae: 0.1020\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0467 - mae: 0.1701 - val_loss: 0.0166 - val_mae: 0.0981\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0469 - mae: 0.1700 - val_loss: 0.0164 - val_mae: 0.0990\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0444 - mae: 0.1661 - val_loss: 0.0170 - val_mae: 0.0983\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0448 - mae: 0.1665 - val_loss: 0.0168 - val_mae: 0.0983\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0441 - mae: 0.1654 - val_loss: 0.0211 - val_mae: 0.1141\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0442 - mae: 0.1658 - val_loss: 0.0163 - val_mae: 0.0972\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0435 - mae: 0.1636 - val_loss: 0.0163 - val_mae: 0.0974\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0441 - mae: 0.1651 - val_loss: 0.0161 - val_mae: 0.0968\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0432 - mae: 0.1638 - val_loss: 0.0200 - val_mae: 0.1059\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0427 - mae: 0.1624 - val_loss: 0.0159 - val_mae: 0.0951\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0435 - mae: 0.1643 - val_loss: 0.0196 - val_mae: 0.1098\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0415 - mae: 0.1607 - val_loss: 0.0162 - val_mae: 0.0967\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0421 - mae: 0.1617 - val_loss: 0.0156 - val_mae: 0.0952\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0425 - mae: 0.1623 - val_loss: 0.0164 - val_mae: 0.0981\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0413 - mae: 0.1603 - val_loss: 0.0193 - val_mae: 0.1073\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0426 - mae: 0.1623 - val_loss: 0.0201 - val_mae: 0.1065\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0421 - mae: 0.1613 - val_loss: 0.0192 - val_mae: 0.1082\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0416 - mae: 0.1604 - val_loss: 0.0183 - val_mae: 0.1057\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0407 - mae: 0.1586 - val_loss: 0.0182 - val_mae: 0.1043\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0404 - mae: 0.1584 - val_loss: 0.0182 - val_mae: 0.1060\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0405 - mae: 0.1588 - val_loss: 0.0182 - val_mae: 0.1033\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0406 - mae: 0.1584 - val_loss: 0.0156 - val_mae: 0.0956\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0398 - mae: 0.1575 - val_loss: 0.0170 - val_mae: 0.1003\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0402 - mae: 0.1586 - val_loss: 0.0166 - val_mae: 0.0987\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0395 - mae: 0.1562 - val_loss: 0.0152 - val_mae: 0.0938\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 2s 99us/step - loss: 0.0392 - mae: 0.1553 - val_loss: 0.0168 - val_mae: 0.1001\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0390 - mae: 0.1558 - val_loss: 0.0157 - val_mae: 0.0962\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0386 - mae: 0.1547 - val_loss: 0.0170 - val_mae: 0.1002\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0386 - mae: 0.1547 - val_loss: 0.0173 - val_mae: 0.1008\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0384 - mae: 0.1541 - val_loss: 0.0154 - val_mae: 0.0955\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 2s 101us/step - loss: 0.0378 - mae: 0.1531 - val_loss: 0.0154 - val_mae: 0.0937\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.0378 - mae: 0.1532 - val_loss: 0.0160 - val_mae: 0.0965\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0387 - mae: 0.1546 - val_loss: 0.0159 - val_mae: 0.0961\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0381 - mae: 0.1529 - val_loss: 0.0157 - val_mae: 0.0952\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0365 - mae: 0.1503 - val_loss: 0.0183 - val_mae: 0.1071\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0368 - mae: 0.1514 - val_loss: 0.0154 - val_mae: 0.0946\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0375 - mae: 0.1517 - val_loss: 0.0161 - val_mae: 0.0954\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0377 - mae: 0.1521 - val_loss: 0.0153 - val_mae: 0.0931\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 49us/step - loss: 0.0366 - mae: 0.1503 - val_loss: 0.0159 - val_mae: 0.0961\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0364 - mae: 0.1497 - val_loss: 0.0163 - val_mae: 0.0975\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0364 - mae: 0.1498 - val_loss: 0.0157 - val_mae: 0.0971\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0361 - mae: 0.1493 - val_loss: 0.0154 - val_mae: 0.0950\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0357 - mae: 0.1484 - val_loss: 0.0170 - val_mae: 0.1009\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0360 - mae: 0.1495 - val_loss: 0.0171 - val_mae: 0.1011\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0351 - mae: 0.1477 - val_loss: 0.0175 - val_mae: 0.1011\n",
      "Fold 9\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 4s 197us/step - loss: 2.7971 - mae: 1.1739 - val_loss: 0.6319 - val_mae: 0.5848\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.3712 - mae: 0.4566 - val_loss: 0.1022 - val_mae: 0.2484\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.1573 - mae: 0.3104 - val_loss: 0.0498 - val_mae: 0.1695\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1250 - mae: 0.2781 - val_loss: 0.0360 - val_mae: 0.1431\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1077 - mae: 0.2586 - val_loss: 0.0348 - val_mae: 0.1453\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.1002 - mae: 0.2506 - val_loss: 0.0342 - val_mae: 0.1419\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0953 - mae: 0.2427 - val_loss: 0.0312 - val_mae: 0.1359\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0892 - mae: 0.2360 - val_loss: 0.0333 - val_mae: 0.1439\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0826 - mae: 0.2275 - val_loss: 0.0303 - val_mae: 0.1375\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0791 - mae: 0.2217 - val_loss: 0.0264 - val_mae: 0.1247\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0762 - mae: 0.2176 - val_loss: 0.0295 - val_mae: 0.1325\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0763 - mae: 0.2181 - val_loss: 0.0253 - val_mae: 0.1239\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0735 - mae: 0.2138 - val_loss: 0.0248 - val_mae: 0.1215\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0699 - mae: 0.2092 - val_loss: 0.0242 - val_mae: 0.1183\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0691 - mae: 0.2076 - val_loss: 0.0233 - val_mae: 0.1175\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0662 - mae: 0.2034 - val_loss: 0.0281 - val_mae: 0.1319\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0655 - mae: 0.2015 - val_loss: 0.0536 - val_mae: 0.1944\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0643 - mae: 0.2002 - val_loss: 0.0263 - val_mae: 0.1258\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0613 - mae: 0.1956 - val_loss: 0.0233 - val_mae: 0.1193\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0602 - mae: 0.1934 - val_loss: 0.0200 - val_mae: 0.1064\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0599 - mae: 0.1936 - val_loss: 0.0201 - val_mae: 0.1088\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0569 - mae: 0.1881 - val_loss: 0.0216 - val_mae: 0.1131\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0564 - mae: 0.1872 - val_loss: 0.0226 - val_mae: 0.1166\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0557 - mae: 0.1863 - val_loss: 0.0202 - val_mae: 0.1072\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0539 - mae: 0.1838 - val_loss: 0.0238 - val_mae: 0.1232\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0550 - mae: 0.1844 - val_loss: 0.0213 - val_mae: 0.1105\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0515 - mae: 0.1785 - val_loss: 0.0235 - val_mae: 0.1208\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0532 - mae: 0.1819 - val_loss: 0.0188 - val_mae: 0.1035\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0512 - mae: 0.1783 - val_loss: 0.0195 - val_mae: 0.1067\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0500 - mae: 0.1754 - val_loss: 0.0295 - val_mae: 0.1401\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0506 - mae: 0.1773 - val_loss: 0.0228 - val_mae: 0.1180\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0488 - mae: 0.1736 - val_loss: 0.0219 - val_mae: 0.1166\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0478 - mae: 0.1720 - val_loss: 0.0185 - val_mae: 0.1011\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0463 - mae: 0.1690 - val_loss: 0.0187 - val_mae: 0.1029\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0458 - mae: 0.1679 - val_loss: 0.0190 - val_mae: 0.1028\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0475 - mae: 0.1722 - val_loss: 0.0203 - val_mae: 0.1102\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0470 - mae: 0.1709 - val_loss: 0.0286 - val_mae: 0.1342\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0466 - mae: 0.1698 - val_loss: 0.0188 - val_mae: 0.1033\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0442 - mae: 0.1652 - val_loss: 0.0181 - val_mae: 0.1003\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0434 - mae: 0.1633 - val_loss: 0.0194 - val_mae: 0.1064\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0431 - mae: 0.1636 - val_loss: 0.0220 - val_mae: 0.1172\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0441 - mae: 0.1651 - val_loss: 0.0171 - val_mae: 0.0981\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0433 - mae: 0.1642 - val_loss: 0.0193 - val_mae: 0.1069\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0427 - mae: 0.1615 - val_loss: 0.0177 - val_mae: 0.1011\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0426 - mae: 0.1622 - val_loss: 0.0187 - val_mae: 0.1039\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0412 - mae: 0.1598 - val_loss: 0.0183 - val_mae: 0.1021\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0444 - mae: 0.1659 - val_loss: 0.0185 - val_mae: 0.1027\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0414 - mae: 0.1608 - val_loss: 0.0194 - val_mae: 0.1059\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0420 - mae: 0.1613 - val_loss: 0.0210 - val_mae: 0.1088\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0403 - mae: 0.1585 - val_loss: 0.0171 - val_mae: 0.0983\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0408 - mae: 0.1592 - val_loss: 0.0169 - val_mae: 0.0977\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0404 - mae: 0.1587 - val_loss: 0.0171 - val_mae: 0.0983\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0414 - mae: 0.1604 - val_loss: 0.0174 - val_mae: 0.0987\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0393 - mae: 0.1556 - val_loss: 0.0178 - val_mae: 0.0982\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0401 - mae: 0.1581 - val_loss: 0.0179 - val_mae: 0.1009\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0393 - mae: 0.1561 - val_loss: 0.0179 - val_mae: 0.1009\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0390 - mae: 0.1551 - val_loss: 0.0168 - val_mae: 0.0963\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0394 - mae: 0.1560 - val_loss: 0.0172 - val_mae: 0.0985\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0388 - mae: 0.1548 - val_loss: 0.0188 - val_mae: 0.1030\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0381 - mae: 0.1536 - val_loss: 0.0178 - val_mae: 0.1007\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0387 - mae: 0.1547 - val_loss: 0.0164 - val_mae: 0.0962\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0384 - mae: 0.1547 - val_loss: 0.0173 - val_mae: 0.0998\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0369 - mae: 0.1513 - val_loss: 0.0193 - val_mae: 0.1038\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0366 - mae: 0.1504 - val_loss: 0.0173 - val_mae: 0.0990\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0377 - mae: 0.1529 - val_loss: 0.0197 - val_mae: 0.1047\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0372 - mae: 0.1512 - val_loss: 0.0179 - val_mae: 0.0980\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0375 - mae: 0.1531 - val_loss: 0.0179 - val_mae: 0.1015\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0377 - mae: 0.1525 - val_loss: 0.0197 - val_mae: 0.1053\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0374 - mae: 0.1520 - val_loss: 0.0179 - val_mae: 0.1005\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0371 - mae: 0.1516 - val_loss: 0.0177 - val_mae: 0.1003\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0366 - mae: 0.1501 - val_loss: 0.0162 - val_mae: 0.0944\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0359 - mae: 0.1492 - val_loss: 0.0170 - val_mae: 0.0984\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0358 - mae: 0.1487 - val_loss: 0.0167 - val_mae: 0.0976\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0360 - mae: 0.1490 - val_loss: 0.0172 - val_mae: 0.0988\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0359 - mae: 0.1491 - val_loss: 0.0179 - val_mae: 0.1006\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0362 - mae: 0.1495 - val_loss: 0.0165 - val_mae: 0.0963\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0359 - mae: 0.1488 - val_loss: 0.0173 - val_mae: 0.0991\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0348 - mae: 0.1466 - val_loss: 0.0160 - val_mae: 0.0944\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0354 - mae: 0.1474 - val_loss: 0.0162 - val_mae: 0.0944\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0347 - mae: 0.1466 - val_loss: 0.0175 - val_mae: 0.0995\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0344 - mae: 0.1458 - val_loss: 0.0200 - val_mae: 0.1078\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0345 - mae: 0.1453 - val_loss: 0.0163 - val_mae: 0.0962\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0340 - mae: 0.1447 - val_loss: 0.0176 - val_mae: 0.1007\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0347 - mae: 0.1467 - val_loss: 0.0175 - val_mae: 0.1001\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0350 - mae: 0.1471 - val_loss: 0.0171 - val_mae: 0.0973\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0344 - mae: 0.1458 - val_loss: 0.0171 - val_mae: 0.0972\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0340 - mae: 0.1449 - val_loss: 0.0173 - val_mae: 0.0994\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 2s 108us/step - loss: 0.0335 - mae: 0.1440 - val_loss: 0.0170 - val_mae: 0.0979\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0334 - mae: 0.1440 - val_loss: 0.0166 - val_mae: 0.0972\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0329 - mae: 0.1422 - val_loss: 0.0180 - val_mae: 0.1004\n",
      "Epoch 91/100\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0339 - mae: 0.1448 - val_loss: 0.0176 - val_mae: 0.0994\n",
      "Epoch 92/100\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0332 - mae: 0.1432 - val_loss: 0.0172 - val_mae: 0.0973\n",
      "Epoch 93/100\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0330 - mae: 0.1427 - val_loss: 0.0170 - val_mae: 0.0980\n",
      "Epoch 94/100\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0333 - mae: 0.1440 - val_loss: 0.0163 - val_mae: 0.0943\n",
      "Epoch 95/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0325 - mae: 0.1410 - val_loss: 0.0163 - val_mae: 0.0952\n",
      "Epoch 96/100\n",
      "18900/18900 [==============================] - 2s 103us/step - loss: 0.0321 - mae: 0.1409 - val_loss: 0.0187 - val_mae: 0.1012\n",
      "Epoch 97/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0328 - mae: 0.1421 - val_loss: 0.0168 - val_mae: 0.0968\n",
      "Epoch 98/100\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0324 - mae: 0.1412 - val_loss: 0.0170 - val_mae: 0.0980\n",
      "Fold 10\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/100\n",
      "18900/18900 [==============================] - 2s 130us/step - loss: 3.2950 - mae: 1.2759 - val_loss: 0.7861 - val_mae: 0.6718\n",
      "Epoch 2/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.4771 - mae: 0.5163 - val_loss: 0.1254 - val_mae: 0.2670\n",
      "Epoch 3/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.1617 - mae: 0.3131 - val_loss: 0.0460 - val_mae: 0.1620\n",
      "Epoch 4/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.1253 - mae: 0.2783 - val_loss: 0.0399 - val_mae: 0.1500\n",
      "Epoch 5/100\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1151 - mae: 0.2672 - val_loss: 0.0338 - val_mae: 0.1382\n",
      "Epoch 6/100\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.1056 - mae: 0.2565 - val_loss: 0.0295 - val_mae: 0.1280\n",
      "Epoch 7/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0986 - mae: 0.2484 - val_loss: 0.0373 - val_mae: 0.1455\n",
      "Epoch 8/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0949 - mae: 0.2442 - val_loss: 0.0347 - val_mae: 0.1442\n",
      "Epoch 9/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0918 - mae: 0.2396 - val_loss: 0.0345 - val_mae: 0.1400\n",
      "Epoch 10/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0878 - mae: 0.2343 - val_loss: 0.0267 - val_mae: 0.1237\n",
      "Epoch 11/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0843 - mae: 0.2302 - val_loss: 0.0276 - val_mae: 0.1272\n",
      "Epoch 12/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0841 - mae: 0.2284 - val_loss: 0.0269 - val_mae: 0.1238\n",
      "Epoch 13/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0798 - mae: 0.2241 - val_loss: 0.0244 - val_mae: 0.1201\n",
      "Epoch 14/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0768 - mae: 0.2186 - val_loss: 0.0281 - val_mae: 0.1294\n",
      "Epoch 15/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0772 - mae: 0.2196 - val_loss: 0.0239 - val_mae: 0.1187\n",
      "Epoch 16/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0760 - mae: 0.2175 - val_loss: 0.0258 - val_mae: 0.1234\n",
      "Epoch 17/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0739 - mae: 0.2148 - val_loss: 0.0247 - val_mae: 0.1199\n",
      "Epoch 18/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0729 - mae: 0.2140 - val_loss: 0.0267 - val_mae: 0.1281\n",
      "Epoch 19/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0742 - mae: 0.2153 - val_loss: 0.0211 - val_mae: 0.1099\n",
      "Epoch 20/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0691 - mae: 0.2078 - val_loss: 0.0268 - val_mae: 0.1260\n",
      "Epoch 21/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0675 - mae: 0.2045 - val_loss: 0.0222 - val_mae: 0.1117\n",
      "Epoch 22/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0673 - mae: 0.2049 - val_loss: 0.0202 - val_mae: 0.1064\n",
      "Epoch 23/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0668 - mae: 0.2045 - val_loss: 0.0205 - val_mae: 0.1080\n",
      "Epoch 24/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0651 - mae: 0.2018 - val_loss: 0.0209 - val_mae: 0.1075\n",
      "Epoch 25/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0639 - mae: 0.2000 - val_loss: 0.0201 - val_mae: 0.1066\n",
      "Epoch 26/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0638 - mae: 0.1998 - val_loss: 0.0303 - val_mae: 0.1387\n",
      "Epoch 27/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0641 - mae: 0.1996 - val_loss: 0.0200 - val_mae: 0.1069\n",
      "Epoch 28/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0619 - mae: 0.1964 - val_loss: 0.0213 - val_mae: 0.1108\n",
      "Epoch 29/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0610 - mae: 0.1946 - val_loss: 0.0205 - val_mae: 0.1080\n",
      "Epoch 30/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0604 - mae: 0.1945 - val_loss: 0.0224 - val_mae: 0.1151\n",
      "Epoch 31/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0572 - mae: 0.1885 - val_loss: 0.0248 - val_mae: 0.1243\n",
      "Epoch 32/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0580 - mae: 0.1899 - val_loss: 0.0201 - val_mae: 0.1087\n",
      "Epoch 33/100\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.0583 - mae: 0.1908 - val_loss: 0.0221 - val_mae: 0.1149\n",
      "Epoch 34/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0567 - mae: 0.1875 - val_loss: 0.0180 - val_mae: 0.1015\n",
      "Epoch 35/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0545 - mae: 0.1839 - val_loss: 0.0222 - val_mae: 0.1151\n",
      "Epoch 36/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0541 - mae: 0.1834 - val_loss: 0.0196 - val_mae: 0.1068\n",
      "Epoch 37/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0550 - mae: 0.1845 - val_loss: 0.0208 - val_mae: 0.1119\n",
      "Epoch 38/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0523 - mae: 0.1800 - val_loss: 0.0199 - val_mae: 0.1070\n",
      "Epoch 39/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0526 - mae: 0.1809 - val_loss: 0.0200 - val_mae: 0.1085\n",
      "Epoch 40/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0506 - mae: 0.1773 - val_loss: 0.0181 - val_mae: 0.1006\n",
      "Epoch 41/100\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0519 - mae: 0.1793 - val_loss: 0.0212 - val_mae: 0.1128\n",
      "Epoch 42/100\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0499 - mae: 0.1764 - val_loss: 0.0170 - val_mae: 0.0974\n",
      "Epoch 43/100\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0494 - mae: 0.1756 - val_loss: 0.0175 - val_mae: 0.0996\n",
      "Epoch 44/100\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0500 - mae: 0.1763 - val_loss: 0.0321 - val_mae: 0.1449\n",
      "Epoch 45/100\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0492 - mae: 0.1748 - val_loss: 0.0282 - val_mae: 0.1349\n",
      "Epoch 46/100\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0471 - mae: 0.1714 - val_loss: 0.0175 - val_mae: 0.0990\n",
      "Epoch 47/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0498 - mae: 0.1759 - val_loss: 0.0221 - val_mae: 0.1152\n",
      "Epoch 48/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0477 - mae: 0.1713 - val_loss: 0.0168 - val_mae: 0.0981\n",
      "Epoch 49/100\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0467 - mae: 0.1705 - val_loss: 0.0182 - val_mae: 0.1023\n",
      "Epoch 50/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0482 - mae: 0.1733 - val_loss: 0.0168 - val_mae: 0.0975\n",
      "Epoch 51/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0453 - mae: 0.1681 - val_loss: 0.0203 - val_mae: 0.1088\n",
      "Epoch 52/100\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0461 - mae: 0.1687 - val_loss: 0.0194 - val_mae: 0.1070\n",
      "Epoch 53/100\n",
      "18900/18900 [==============================] - 2s 108us/step - loss: 0.0451 - mae: 0.1673 - val_loss: 0.0168 - val_mae: 0.0975\n",
      "Epoch 54/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0459 - mae: 0.1680 - val_loss: 0.0198 - val_mae: 0.1058\n",
      "Epoch 55/100\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0445 - mae: 0.1664 - val_loss: 0.0168 - val_mae: 0.0970\n",
      "Epoch 56/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0436 - mae: 0.1644 - val_loss: 0.0173 - val_mae: 0.0981\n",
      "Epoch 57/100\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0435 - mae: 0.1646 - val_loss: 0.0174 - val_mae: 0.0992\n",
      "Epoch 58/100\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0440 - mae: 0.1658 - val_loss: 0.0173 - val_mae: 0.1005\n",
      "Epoch 59/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0436 - mae: 0.1645 - val_loss: 0.0165 - val_mae: 0.0967\n",
      "Epoch 60/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0423 - mae: 0.1619 - val_loss: 0.0176 - val_mae: 0.1004\n",
      "Epoch 61/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0429 - mae: 0.1636 - val_loss: 0.0164 - val_mae: 0.0968\n",
      "Epoch 62/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0427 - mae: 0.1628 - val_loss: 0.0185 - val_mae: 0.1032\n",
      "Epoch 63/100\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0429 - mae: 0.1637 - val_loss: 0.0166 - val_mae: 0.0972\n",
      "Epoch 64/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0426 - mae: 0.1629 - val_loss: 0.0172 - val_mae: 0.0983\n",
      "Epoch 65/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0420 - mae: 0.1620 - val_loss: 0.0179 - val_mae: 0.1010\n",
      "Epoch 66/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0416 - mae: 0.1606 - val_loss: 0.0167 - val_mae: 0.0969\n",
      "Epoch 67/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0413 - mae: 0.1604 - val_loss: 0.0171 - val_mae: 0.0981\n",
      "Epoch 68/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0414 - mae: 0.1606 - val_loss: 0.0182 - val_mae: 0.1003\n",
      "Epoch 69/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0414 - mae: 0.1605 - val_loss: 0.0271 - val_mae: 0.1317\n",
      "Epoch 70/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0408 - mae: 0.1590 - val_loss: 0.0181 - val_mae: 0.1009\n",
      "Epoch 71/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0409 - mae: 0.1595 - val_loss: 0.0176 - val_mae: 0.0997\n",
      "Epoch 72/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0396 - mae: 0.1567 - val_loss: 0.0199 - val_mae: 0.1077\n",
      "Epoch 73/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0395 - mae: 0.1569 - val_loss: 0.0192 - val_mae: 0.1020\n",
      "Epoch 74/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0390 - mae: 0.1552 - val_loss: 0.0167 - val_mae: 0.0971\n",
      "Epoch 75/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0393 - mae: 0.1562 - val_loss: 0.0161 - val_mae: 0.0956\n",
      "Epoch 76/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0391 - mae: 0.1562 - val_loss: 0.0173 - val_mae: 0.0982\n",
      "Epoch 77/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0394 - mae: 0.1564 - val_loss: 0.0162 - val_mae: 0.0948\n",
      "Epoch 78/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0386 - mae: 0.1550 - val_loss: 0.0175 - val_mae: 0.0997\n",
      "Epoch 79/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0379 - mae: 0.1534 - val_loss: 0.0164 - val_mae: 0.0961\n",
      "Epoch 80/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0386 - mae: 0.1546 - val_loss: 0.0160 - val_mae: 0.0943\n",
      "Epoch 81/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0375 - mae: 0.1523 - val_loss: 0.0173 - val_mae: 0.0980\n",
      "Epoch 82/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0375 - mae: 0.1526 - val_loss: 0.0156 - val_mae: 0.0941\n",
      "Epoch 83/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0380 - mae: 0.1532 - val_loss: 0.0186 - val_mae: 0.1043\n",
      "Epoch 84/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0373 - mae: 0.1520 - val_loss: 0.0179 - val_mae: 0.1007\n",
      "Epoch 85/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0364 - mae: 0.1495 - val_loss: 0.0172 - val_mae: 0.0988\n",
      "Epoch 86/100\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0378 - mae: 0.1524 - val_loss: 0.0162 - val_mae: 0.0942\n",
      "Epoch 87/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0366 - mae: 0.1500 - val_loss: 0.0163 - val_mae: 0.0949\n",
      "Epoch 88/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0372 - mae: 0.1511 - val_loss: 0.0166 - val_mae: 0.0971\n",
      "Epoch 89/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0362 - mae: 0.1498 - val_loss: 0.0165 - val_mae: 0.0956\n",
      "Epoch 90/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0368 - mae: 0.1507 - val_loss: 0.0188 - val_mae: 0.1058\n",
      "Epoch 91/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0360 - mae: 0.1493 - val_loss: 0.0172 - val_mae: 0.0979\n",
      "Epoch 92/100\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0357 - mae: 0.1484 - val_loss: 0.0159 - val_mae: 0.0945\n",
      "Epoch 93/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0355 - mae: 0.1489 - val_loss: 0.0162 - val_mae: 0.0944\n",
      "Epoch 94/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0356 - mae: 0.1478 - val_loss: 0.0169 - val_mae: 0.0977\n",
      "Epoch 95/100\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0356 - mae: 0.1489 - val_loss: 0.0172 - val_mae: 0.0985\n",
      "Epoch 96/100\n",
      "18900/18900 [==============================] - 1s 52us/step - loss: 0.0349 - mae: 0.1467 - val_loss: 0.0162 - val_mae: 0.0964\n",
      "Epoch 97/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0351 - mae: 0.1476 - val_loss: 0.0161 - val_mae: 0.0951\n",
      "Epoch 98/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0354 - mae: 0.1479 - val_loss: 0.0163 - val_mae: 0.0955\n",
      "Epoch 99/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0335 - mae: 0.1435 - val_loss: 0.0163 - val_mae: 0.0957\n",
      "Epoch 100/100\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0336 - mae: 0.1441 - val_loss: 0.0157 - val_mae: 0.0948\n",
      "CV score: 34.89531\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 20, restore_best_weights = True)\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, target)):\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation = \"relu\", input_shape = (train[trn_idx].shape[1],)))\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation = \"linear\"))\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = [\"mae\"])\n",
    "    \n",
    "    history = model.fit(train[trn_idx], \n",
    "                                target[trn_idx], \n",
    "                                batch_size = batch_size, \n",
    "                                epochs = epochs, \n",
    "                                verbose = 1,\n",
    "                                validation_data = (train[val_idx], target[val_idx]),\n",
    "                                callbacks = [early_stopping])\n",
    "    \n",
    "    oof[val_idx] = model.predict(train[val_idx]).reshape(len(train[val_idx]), )\n",
    "    predictions += model.predict(test).reshape(len(test), ) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_absolute_error(np.expm1(target), np.expm1(oof))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "# mae\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"mae\"], label = \"mae\", marker = \"o\")\n",
    "plt.plot(history.history[\"val_mae\"], label = \"val_mae\", marker = \"o\")\n",
    "#plt.xticks(np.arange())\n",
    "#plt.yticks(np.arange())\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"mae\")\n",
    "#plt.title(\"\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.grid(color = 'gray', alpha = 0.2)\n",
    "\n",
    "# loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label = \"loss\", marker = \"o\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\", marker = \"o\")\n",
    "#plt.xticks(np.arange())\n",
    "#plt.yticks(np.arange())\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.title(\"\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.grid(color = 'gray', alpha = 0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出用ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.expm1(predictions)\n",
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"y\"] = predictions\n",
    "sub_df.to_csv(\"./output/NN_k-fold10_epoch100_Dropout0.1_averaging.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
