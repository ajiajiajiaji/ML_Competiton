{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./input/train_data.csv\")\n",
    "test_df = pd.read_csv(\"./input/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape： (21000, 13)\n",
      "test shape： (9000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape：\", train_df.shape)\n",
    "print(\"test shape：\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "def preprocess(df):\n",
    "    df[\"area\"] = LabelEncoder().fit_transform(df[\"area\"])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fea_eng(df):\n",
    "    #数値系\n",
    "    #家族の人数\n",
    "    df[\"family_num\"] = df[\"partner\"] + df[\"num_child\"]\n",
    "    \n",
    "    #年間の勤務時間\n",
    "    df[\"work_time_per_year\"] = 8*245*df[\"service_length\"] + 12*df[\"overtime\"]*df[\"service_length\"]\n",
    "    \n",
    "    #自由時間\n",
    "    df[\"free_time_per_year\"] = 24*365 - 8*365 - df[\"study_time\"]*48 - df[\"overtime\"]*12 - df[\"commute\"]*365\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35 ms, sys: 8.42 ms, total: 43.4 ms\n",
      "Wall time: 58.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = preprocess(train_df)\n",
    "train_df = fea_eng(train_df)\n",
    "\n",
    "test_df = preprocess(test_df)\n",
    "test_df = fea_eng(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>partner</th>\n",
       "      <th>num_child</th>\n",
       "      <th>education</th>\n",
       "      <th>service_length</th>\n",
       "      <th>study_time</th>\n",
       "      <th>commute</th>\n",
       "      <th>overtime</th>\n",
       "      <th>salary</th>\n",
       "      <th>family_num</th>\n",
       "      <th>work_time_per_year</th>\n",
       "      <th>free_time_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>428.074887</td>\n",
       "      <td>3</td>\n",
       "      <td>49689.6</td>\n",
       "      <td>5049.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>317.930517</td>\n",
       "      <td>0</td>\n",
       "      <td>27414.4</td>\n",
       "      <td>5003.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>357.350316</td>\n",
       "      <td>0</td>\n",
       "      <td>30279.2</td>\n",
       "      <td>5299.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>201.310911</td>\n",
       "      <td>0</td>\n",
       "      <td>8132.8</td>\n",
       "      <td>5476.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>178.067475</td>\n",
       "      <td>0</td>\n",
       "      <td>10094.0</td>\n",
       "      <td>5564.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  position  age  area  sex  partner  num_child  education  \\\n",
       "0   0         1   44    24    2        1          2          1   \n",
       "1   1         2   31    10    1        0          0          0   \n",
       "2   2         2   36    14    1        0          0          2   \n",
       "3   3         0   22    26    2        0          0          0   \n",
       "4   4         0   25    46    2        0          0          1   \n",
       "\n",
       "   service_length  study_time  commute  overtime      salary  family_num  \\\n",
       "0              24         2.0      1.6       9.2  428.074887           3   \n",
       "1              13         9.0      0.7      12.4  317.930517           0   \n",
       "2              14         4.0      0.4      16.9  357.350316           0   \n",
       "3               4         3.0      0.4       6.1  201.310911           0   \n",
       "4               5         3.0      0.2       4.9  178.067475           0   \n",
       "\n",
       "   work_time_per_year  free_time_per_year  \n",
       "0             49689.6              5049.6  \n",
       "1             27414.4              5003.7  \n",
       "2             30279.2              5299.2  \n",
       "3              8132.8              5476.8  \n",
       "4             10094.0              5564.2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>partner</th>\n",
       "      <th>num_child</th>\n",
       "      <th>education</th>\n",
       "      <th>service_length</th>\n",
       "      <th>study_time</th>\n",
       "      <th>commute</th>\n",
       "      <th>overtime</th>\n",
       "      <th>family_num</th>\n",
       "      <th>work_time_per_year</th>\n",
       "      <th>free_time_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6</td>\n",
       "      <td>40477.6</td>\n",
       "      <td>4964.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5434.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3975.2</td>\n",
       "      <td>5278.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19600.0</td>\n",
       "      <td>5586.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>47867.6</td>\n",
       "      <td>5392.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  position  age  area  sex  partner  num_child  education  \\\n",
       "0   0         3   39    46    2        1          5          1   \n",
       "1   1         1   31    11    1        0          0          4   \n",
       "2   2         0   20    24    2        1          2          0   \n",
       "3   3         0   28     0    2        0          0          0   \n",
       "4   4         1   41    23    2        0          0          0   \n",
       "\n",
       "   service_length  study_time  commute  overtime  family_num  \\\n",
       "0              19         1.0      1.8      14.2           6   \n",
       "1               0         0.0      0.5      18.6           0   \n",
       "2               2         2.0      1.2       2.3           3   \n",
       "3              10         3.0      0.3       0.0           0   \n",
       "4              23         3.0      0.5      10.1           0   \n",
       "\n",
       "   work_time_per_year  free_time_per_year  \n",
       "0             40477.6              4964.6  \n",
       "1                 0.0              5434.3  \n",
       "2              3975.2              5278.4  \n",
       "3             19600.0              5586.5  \n",
       "4             47867.6              5392.3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['id', 'salary', \"position\", \"area\", \"sex\", \"partner\", \"education\", \"age_generation\"]]\n",
    "target = train_df[\"salary\"]\n",
    "target = target.map(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train_df[features].values)\n",
    "test = scaler.fit_transform(test_df[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 3s 153us/step - loss: 3.1225 - mae: 1.2566 - val_loss: 0.7516 - val_mae: 0.6525\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.5240 - mae: 0.5517 - val_loss: 0.1178 - val_mae: 0.2509\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.2621 - mae: 0.4019 - val_loss: 0.0591 - val_mae: 0.1792\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.2065 - mae: 0.3568 - val_loss: 0.0534 - val_mae: 0.1833\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.1791 - mae: 0.3361 - val_loss: 0.0314 - val_mae: 0.1342\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.1612 - mae: 0.3175 - val_loss: 0.0288 - val_mae: 0.1305\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.1499 - mae: 0.3058 - val_loss: 0.0304 - val_mae: 0.1336\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1409 - mae: 0.2970 - val_loss: 0.0338 - val_mae: 0.1445\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1392 - mae: 0.2950 - val_loss: 0.0266 - val_mae: 0.1253\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1295 - mae: 0.2851 - val_loss: 0.0382 - val_mae: 0.1576\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 2s 105us/step - loss: 0.1221 - mae: 0.2761 - val_loss: 0.0297 - val_mae: 0.1370\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.1194 - mae: 0.2737 - val_loss: 0.0248 - val_mae: 0.1230\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.1130 - mae: 0.2648 - val_loss: 0.0260 - val_mae: 0.1282\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1137 - mae: 0.2657 - val_loss: 0.0233 - val_mae: 0.1179\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.1082 - mae: 0.2592 - val_loss: 0.0217 - val_mae: 0.1126\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.1053 - mae: 0.2568 - val_loss: 0.0301 - val_mae: 0.1376\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1044 - mae: 0.2547 - val_loss: 0.0218 - val_mae: 0.1148\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0980 - mae: 0.2467 - val_loss: 0.0222 - val_mae: 0.1137\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0959 - mae: 0.2446 - val_loss: 0.0297 - val_mae: 0.1381\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0959 - mae: 0.2445 - val_loss: 0.0229 - val_mae: 0.1168\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0906 - mae: 0.2381 - val_loss: 0.0204 - val_mae: 0.1115\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0920 - mae: 0.2393 - val_loss: 0.0213 - val_mae: 0.1133\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0876 - mae: 0.2334 - val_loss: 0.0193 - val_mae: 0.1064\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0854 - mae: 0.2311 - val_loss: 0.0221 - val_mae: 0.1181\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0856 - mae: 0.2315 - val_loss: 0.0211 - val_mae: 0.1117\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0839 - mae: 0.2289 - val_loss: 0.0238 - val_mae: 0.1197\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 53us/step - loss: 0.0829 - mae: 0.2279 - val_loss: 0.0218 - val_mae: 0.1151\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0817 - mae: 0.2257 - val_loss: 0.0182 - val_mae: 0.1039\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0791 - mae: 0.2230 - val_loss: 0.0175 - val_mae: 0.1018\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0785 - mae: 0.2212 - val_loss: 0.0197 - val_mae: 0.1088\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0777 - mae: 0.2210 - val_loss: 0.0174 - val_mae: 0.1008\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0772 - mae: 0.2194 - val_loss: 0.0223 - val_mae: 0.1187\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0800 - mae: 0.2236 - val_loss: 0.0177 - val_mae: 0.1020\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.0774 - mae: 0.2196 - val_loss: 0.0337 - val_mae: 0.1469\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0735 - mae: 0.2135 - val_loss: 0.0165 - val_mae: 0.0982\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0743 - mae: 0.2149 - val_loss: 0.0190 - val_mae: 0.1062\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0731 - mae: 0.2136 - val_loss: 0.0193 - val_mae: 0.1061\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0727 - mae: 0.2139 - val_loss: 0.0175 - val_mae: 0.1014\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.0730 - mae: 0.2140 - val_loss: 0.0176 - val_mae: 0.1026\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0712 - mae: 0.2113 - val_loss: 0.0199 - val_mae: 0.1102\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0714 - mae: 0.2114 - val_loss: 0.0191 - val_mae: 0.1074\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0693 - mae: 0.2076 - val_loss: 0.0168 - val_mae: 0.1004\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0688 - mae: 0.2075 - val_loss: 0.0172 - val_mae: 0.1009\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0677 - mae: 0.2059 - val_loss: 0.0179 - val_mae: 0.1027\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0686 - mae: 0.2066 - val_loss: 0.0220 - val_mae: 0.1189\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0669 - mae: 0.2045 - val_loss: 0.0193 - val_mae: 0.1064\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.0679 - mae: 0.2057 - val_loss: 0.0162 - val_mae: 0.0969\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0657 - mae: 0.2031 - val_loss: 0.0195 - val_mae: 0.1093\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0661 - mae: 0.2035 - val_loss: 0.0172 - val_mae: 0.1009\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0648 - mae: 0.2002 - val_loss: 0.0212 - val_mae: 0.1115\n",
      "Fold 2\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 2s 120us/step - loss: 2.8775 - mae: 1.2067 - val_loss: 0.7206 - val_mae: 0.6370\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.5125 - mae: 0.5453 - val_loss: 0.1244 - val_mae: 0.2668\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.2501 - mae: 0.3935 - val_loss: 0.0536 - val_mae: 0.1696\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.2009 - mae: 0.3551 - val_loss: 0.0472 - val_mae: 0.1683\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.1780 - mae: 0.3340 - val_loss: 0.0387 - val_mae: 0.1500\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.1588 - mae: 0.3167 - val_loss: 0.0300 - val_mae: 0.1316\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.1481 - mae: 0.3045 - val_loss: 0.0295 - val_mae: 0.1318\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.1393 - mae: 0.2956 - val_loss: 0.0332 - val_mae: 0.1406\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1321 - mae: 0.2867 - val_loss: 0.0259 - val_mae: 0.1253\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.1275 - mae: 0.2836 - val_loss: 0.0269 - val_mae: 0.1280\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.1211 - mae: 0.2751 - val_loss: 0.0260 - val_mae: 0.1268\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1163 - mae: 0.2700 - val_loss: 0.0230 - val_mae: 0.1176\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.1105 - mae: 0.2635 - val_loss: 0.0263 - val_mae: 0.1284\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.1096 - mae: 0.2614 - val_loss: 0.0224 - val_mae: 0.1152\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.1065 - mae: 0.2586 - val_loss: 0.0254 - val_mae: 0.1242\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1015 - mae: 0.2527 - val_loss: 0.0331 - val_mae: 0.1451\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0996 - mae: 0.2507 - val_loss: 0.0222 - val_mae: 0.1162\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 3s 161us/step - loss: 0.0981 - mae: 0.2474 - val_loss: 0.0202 - val_mae: 0.1097\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 2s 125us/step - loss: 0.0960 - mae: 0.2444 - val_loss: 0.0206 - val_mae: 0.1115\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 2s 103us/step - loss: 0.0917 - mae: 0.2394 - val_loss: 0.0194 - val_mae: 0.1078\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0886 - mae: 0.2345 - val_loss: 0.0212 - val_mae: 0.1142\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.0868 - mae: 0.2320 - val_loss: 0.0194 - val_mae: 0.1083\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0843 - mae: 0.2283 - val_loss: 0.0301 - val_mae: 0.1394\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0868 - mae: 0.2322 - val_loss: 0.0193 - val_mae: 0.1082\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 110us/step - loss: 0.0834 - mae: 0.2282 - val_loss: 0.0205 - val_mae: 0.1127\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 99us/step - loss: 0.0822 - mae: 0.2266 - val_loss: 0.0254 - val_mae: 0.1284\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0799 - mae: 0.2230 - val_loss: 0.0259 - val_mae: 0.1260\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0785 - mae: 0.2211 - val_loss: 0.0204 - val_mae: 0.1099\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 105us/step - loss: 0.0769 - mae: 0.2194 - val_loss: 0.0193 - val_mae: 0.1067\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 2s 115us/step - loss: 0.0767 - mae: 0.2181 - val_loss: 0.0186 - val_mae: 0.1046\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0752 - mae: 0.2164 - val_loss: 0.0190 - val_mae: 0.1062\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0747 - mae: 0.2155 - val_loss: 0.0181 - val_mae: 0.1015\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0742 - mae: 0.2143 - val_loss: 0.0194 - val_mae: 0.1091\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0730 - mae: 0.2133 - val_loss: 0.0193 - val_mae: 0.1083\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0701 - mae: 0.2097 - val_loss: 0.0174 - val_mae: 0.1011\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0697 - mae: 0.2088 - val_loss: 0.0190 - val_mae: 0.1054\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0697 - mae: 0.2090 - val_loss: 0.0185 - val_mae: 0.1047\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0714 - mae: 0.2120 - val_loss: 0.0220 - val_mae: 0.1145\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0702 - mae: 0.2094 - val_loss: 0.0186 - val_mae: 0.1046\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0683 - mae: 0.2062 - val_loss: 0.0215 - val_mae: 0.1147\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0673 - mae: 0.2049 - val_loss: 0.0177 - val_mae: 0.1029\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0659 - mae: 0.2024 - val_loss: 0.0204 - val_mae: 0.1132\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - ETA: 0s - loss: 0.0672 - mae: 0.205 - 2s 85us/step - loss: 0.0673 - mae: 0.2055 - val_loss: 0.0189 - val_mae: 0.1062\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0660 - mae: 0.2031 - val_loss: 0.0213 - val_mae: 0.1144\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 2s 129us/step - loss: 0.0648 - mae: 0.2013 - val_loss: 0.0163 - val_mae: 0.0968\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 121us/step - loss: 0.0633 - mae: 0.1989 - val_loss: 0.0162 - val_mae: 0.0980\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0642 - mae: 0.2000 - val_loss: 0.0160 - val_mae: 0.0978\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 117us/step - loss: 0.0619 - mae: 0.1976 - val_loss: 0.0178 - val_mae: 0.1035\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0625 - mae: 0.1974 - val_loss: 0.0167 - val_mae: 0.0998\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0618 - mae: 0.1969 - val_loss: 0.0168 - val_mae: 0.0980\n",
      "Fold 3\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 2s 119us/step - loss: 3.1167 - mae: 1.2650 - val_loss: 0.7706 - val_mae: 0.6523\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.5370 - mae: 0.5597 - val_loss: 0.1457 - val_mae: 0.2977\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.2663 - mae: 0.4052 - val_loss: 0.0631 - val_mae: 0.1911\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 2s 109us/step - loss: 0.2095 - mae: 0.3618 - val_loss: 0.0459 - val_mae: 0.1601\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.1842 - mae: 0.3398 - val_loss: 0.0402 - val_mae: 0.1525\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1664 - mae: 0.3227 - val_loss: 0.0357 - val_mae: 0.1436\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.1553 - mae: 0.3116 - val_loss: 0.0386 - val_mae: 0.1528\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.1482 - mae: 0.3049 - val_loss: 0.0364 - val_mae: 0.1518\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.1422 - mae: 0.2989 - val_loss: 0.0280 - val_mae: 0.1296\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1357 - mae: 0.2909 - val_loss: 0.0287 - val_mae: 0.1352\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1262 - mae: 0.2822 - val_loss: 0.0249 - val_mae: 0.1248\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.1270 - mae: 0.2819 - val_loss: 0.0248 - val_mae: 0.1239\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.1213 - mae: 0.2763 - val_loss: 0.0213 - val_mae: 0.1137\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1168 - mae: 0.2697 - val_loss: 0.0241 - val_mae: 0.1241\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.1119 - mae: 0.2648 - val_loss: 0.0215 - val_mae: 0.1150\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1116 - mae: 0.2648 - val_loss: 0.0216 - val_mae: 0.1158\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.1065 - mae: 0.2577 - val_loss: 0.0198 - val_mae: 0.1098\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.1047 - mae: 0.2556 - val_loss: 0.0258 - val_mae: 0.1284\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.1037 - mae: 0.2547 - val_loss: 0.0203 - val_mae: 0.1108\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0970 - mae: 0.2467 - val_loss: 0.0276 - val_mae: 0.1359\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0954 - mae: 0.2442 - val_loss: 0.0212 - val_mae: 0.1138\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0963 - mae: 0.2451 - val_loss: 0.0239 - val_mae: 0.1211\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0928 - mae: 0.2407 - val_loss: 0.0224 - val_mae: 0.1192\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0918 - mae: 0.2398 - val_loss: 0.0200 - val_mae: 0.1098\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0886 - mae: 0.2356 - val_loss: 0.0294 - val_mae: 0.1365\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0879 - mae: 0.2345 - val_loss: 0.0320 - val_mae: 0.1430\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0868 - mae: 0.2334 - val_loss: 0.0200 - val_mae: 0.1087\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0833 - mae: 0.2274 - val_loss: 0.0253 - val_mae: 0.1273\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0827 - mae: 0.2274 - val_loss: 0.0223 - val_mae: 0.1186\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0816 - mae: 0.2263 - val_loss: 0.0188 - val_mae: 0.1074\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0819 - mae: 0.2266 - val_loss: 0.0175 - val_mae: 0.1023\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0806 - mae: 0.2235 - val_loss: 0.0191 - val_mae: 0.1058\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0786 - mae: 0.2213 - val_loss: 0.0229 - val_mae: 0.1235\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0792 - mae: 0.2221 - val_loss: 0.0200 - val_mae: 0.1065\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0756 - mae: 0.2174 - val_loss: 0.0173 - val_mae: 0.1025\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0763 - mae: 0.2182 - val_loss: 0.0175 - val_mae: 0.1013\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0751 - mae: 0.2163 - val_loss: 0.0205 - val_mae: 0.1133\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0739 - mae: 0.2151 - val_loss: 0.0185 - val_mae: 0.1062\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0752 - mae: 0.2163 - val_loss: 0.0166 - val_mae: 0.0978\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0721 - mae: 0.2121 - val_loss: 0.0218 - val_mae: 0.1168\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0737 - mae: 0.2147 - val_loss: 0.0185 - val_mae: 0.1028\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0711 - mae: 0.2102 - val_loss: 0.0173 - val_mae: 0.1025\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0691 - mae: 0.2079 - val_loss: 0.0164 - val_mae: 0.0982\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0693 - mae: 0.2076 - val_loss: 0.0205 - val_mae: 0.1076\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0700 - mae: 0.2098 - val_loss: 0.0171 - val_mae: 0.1018\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 97us/step - loss: 0.0694 - mae: 0.2075 - val_loss: 0.0173 - val_mae: 0.0990\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0678 - mae: 0.2056 - val_loss: 0.0183 - val_mae: 0.1057\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 116us/step - loss: 0.0662 - mae: 0.2036 - val_loss: 0.0167 - val_mae: 0.1007\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0666 - mae: 0.2036 - val_loss: 0.0172 - val_mae: 0.1011\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0658 - mae: 0.2025 - val_loss: 0.0172 - val_mae: 0.1005\n",
      "Fold 4\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 4s 216us/step - loss: 2.9185 - mae: 1.2205 - val_loss: 0.6458 - val_mae: 0.6095\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.4961 - mae: 0.5333 - val_loss: 0.0975 - val_mae: 0.2367\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.2461 - mae: 0.3880 - val_loss: 0.0549 - val_mae: 0.1837\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.1960 - mae: 0.3500 - val_loss: 0.0393 - val_mae: 0.1521\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.1774 - mae: 0.3325 - val_loss: 0.0335 - val_mae: 0.1461\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.1564 - mae: 0.3123 - val_loss: 0.0344 - val_mae: 0.1453\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1511 - mae: 0.3071 - val_loss: 0.0253 - val_mae: 0.1251\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 2s 79us/step - loss: 0.1391 - mae: 0.2950 - val_loss: 0.0266 - val_mae: 0.1252\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.1324 - mae: 0.2885 - val_loss: 0.0236 - val_mae: 0.1211\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 2s 115us/step - loss: 0.1241 - mae: 0.2788 - val_loss: 0.0245 - val_mae: 0.1236\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 2s 119us/step - loss: 0.1215 - mae: 0.2759 - val_loss: 0.0252 - val_mae: 0.1247\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.1169 - mae: 0.2713 - val_loss: 0.0229 - val_mae: 0.1193\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.1110 - mae: 0.2634 - val_loss: 0.0289 - val_mae: 0.1386\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1113 - mae: 0.2631 - val_loss: 0.0222 - val_mae: 0.1141\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.1062 - mae: 0.2575 - val_loss: 0.0276 - val_mae: 0.1312\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 2s 103us/step - loss: 0.1044 - mae: 0.2546 - val_loss: 0.0436 - val_mae: 0.1686\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 2s 95us/step - loss: 0.0997 - mae: 0.2500 - val_loss: 0.0293 - val_mae: 0.1390\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 2s 108us/step - loss: 0.0973 - mae: 0.2472 - val_loss: 0.0208 - val_mae: 0.1139\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 2s 107us/step - loss: 0.0935 - mae: 0.2420 - val_loss: 0.0296 - val_mae: 0.1346\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0913 - mae: 0.2380 - val_loss: 0.0213 - val_mae: 0.1130\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0906 - mae: 0.2380 - val_loss: 0.0228 - val_mae: 0.1206\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0873 - mae: 0.2338 - val_loss: 0.0316 - val_mae: 0.1423\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0869 - mae: 0.2333 - val_loss: 0.0204 - val_mae: 0.1129\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0838 - mae: 0.2292 - val_loss: 0.0219 - val_mae: 0.1182\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0818 - mae: 0.2256 - val_loss: 0.0291 - val_mae: 0.1381\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0813 - mae: 0.2255 - val_loss: 0.0181 - val_mae: 0.1032\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0803 - mae: 0.2236 - val_loss: 0.0189 - val_mae: 0.1071\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 2s 79us/step - loss: 0.0799 - mae: 0.2238 - val_loss: 0.0198 - val_mae: 0.1086\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0785 - mae: 0.2217 - val_loss: 0.0213 - val_mae: 0.1134\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0775 - mae: 0.2202 - val_loss: 0.0199 - val_mae: 0.1088\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0760 - mae: 0.2178 - val_loss: 0.0175 - val_mae: 0.1020\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0768 - mae: 0.2195 - val_loss: 0.0182 - val_mae: 0.1048\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0771 - mae: 0.2200 - val_loss: 0.0188 - val_mae: 0.1064\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0740 - mae: 0.2149 - val_loss: 0.0203 - val_mae: 0.1097\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0732 - mae: 0.2128 - val_loss: 0.0207 - val_mae: 0.1130\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0729 - mae: 0.2131 - val_loss: 0.0186 - val_mae: 0.1045\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0713 - mae: 0.2100 - val_loss: 0.0213 - val_mae: 0.1144\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0709 - mae: 0.2105 - val_loss: 0.0189 - val_mae: 0.1072\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0708 - mae: 0.2107 - val_loss: 0.0171 - val_mae: 0.1007\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0703 - mae: 0.2095 - val_loss: 0.0163 - val_mae: 0.0977\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0695 - mae: 0.2090 - val_loss: 0.0178 - val_mae: 0.1043\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0689 - mae: 0.2076 - val_loss: 0.0190 - val_mae: 0.1072\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0683 - mae: 0.2062 - val_loss: 0.0171 - val_mae: 0.1008\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0661 - mae: 0.2028 - val_loss: 0.0169 - val_mae: 0.0995\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0674 - mae: 0.2050 - val_loss: 0.0173 - val_mae: 0.1013\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0671 - mae: 0.2044 - val_loss: 0.0194 - val_mae: 0.1068\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0656 - mae: 0.2027 - val_loss: 0.0204 - val_mae: 0.1103\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0645 - mae: 0.2011 - val_loss: 0.0173 - val_mae: 0.1002\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0641 - mae: 0.2006 - val_loss: 0.0162 - val_mae: 0.0961\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0638 - mae: 0.1998 - val_loss: 0.0168 - val_mae: 0.1005\n",
      "Fold 5\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 3s 158us/step - loss: 3.0108 - mae: 1.2358 - val_loss: 0.7115 - val_mae: 0.6514\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.5219 - mae: 0.5518 - val_loss: 0.1147 - val_mae: 0.2651\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.2514 - mae: 0.3948 - val_loss: 0.0592 - val_mae: 0.1903\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.2039 - mae: 0.3575 - val_loss: 0.0397 - val_mae: 0.1535\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.1748 - mae: 0.3306 - val_loss: 0.0364 - val_mae: 0.1479\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.1613 - mae: 0.3175 - val_loss: 0.0362 - val_mae: 0.1465\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1561 - mae: 0.3126 - val_loss: 0.0294 - val_mae: 0.1326\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1434 - mae: 0.2992 - val_loss: 0.0387 - val_mae: 0.1595\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.1355 - mae: 0.2923 - val_loss: 0.0365 - val_mae: 0.1555\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.1300 - mae: 0.2857 - val_loss: 0.0275 - val_mae: 0.1283\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1260 - mae: 0.2810 - val_loss: 0.0255 - val_mae: 0.1261\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.1184 - mae: 0.2729 - val_loss: 0.0265 - val_mae: 0.1271\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1149 - mae: 0.2697 - val_loss: 0.0222 - val_mae: 0.1157\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.1119 - mae: 0.2641 - val_loss: 0.0253 - val_mae: 0.1264\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.1071 - mae: 0.2587 - val_loss: 0.0262 - val_mae: 0.1272\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.1036 - mae: 0.2545 - val_loss: 0.0221 - val_mae: 0.1156\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.1009 - mae: 0.2513 - val_loss: 0.0232 - val_mae: 0.1174\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0966 - mae: 0.2454 - val_loss: 0.0190 - val_mae: 0.1075\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0941 - mae: 0.2436 - val_loss: 0.0194 - val_mae: 0.1092\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0926 - mae: 0.2404 - val_loss: 0.0226 - val_mae: 0.1162\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0898 - mae: 0.2359 - val_loss: 0.0218 - val_mae: 0.1149\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0889 - mae: 0.2366 - val_loss: 0.0303 - val_mae: 0.1397\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0857 - mae: 0.2313 - val_loss: 0.0192 - val_mae: 0.1068\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0860 - mae: 0.2315 - val_loss: 0.0196 - val_mae: 0.1089\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0837 - mae: 0.2290 - val_loss: 0.0259 - val_mae: 0.1292\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0836 - mae: 0.2284 - val_loss: 0.0259 - val_mae: 0.1294\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0816 - mae: 0.2261 - val_loss: 0.0208 - val_mae: 0.1127\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0815 - mae: 0.2254 - val_loss: 0.0173 - val_mae: 0.1011\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0793 - mae: 0.2226 - val_loss: 0.0216 - val_mae: 0.1149\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0784 - mae: 0.2208 - val_loss: 0.0193 - val_mae: 0.1070\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0793 - mae: 0.2225 - val_loss: 0.0206 - val_mae: 0.1111\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0747 - mae: 0.2159 - val_loss: 0.0170 - val_mae: 0.1001\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0756 - mae: 0.2169 - val_loss: 0.0218 - val_mae: 0.1146\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0727 - mae: 0.2138 - val_loss: 0.0171 - val_mae: 0.1007\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0743 - mae: 0.2159 - val_loss: 0.0188 - val_mae: 0.1057\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0733 - mae: 0.2138 - val_loss: 0.0188 - val_mae: 0.1053\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0724 - mae: 0.2122 - val_loss: 0.0194 - val_mae: 0.1083\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0709 - mae: 0.2106 - val_loss: 0.0174 - val_mae: 0.1015\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0708 - mae: 0.2104 - val_loss: 0.0170 - val_mae: 0.0999\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0703 - mae: 0.2097 - val_loss: 0.0271 - val_mae: 0.1256\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0711 - mae: 0.2113 - val_loss: 0.0180 - val_mae: 0.1025\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0717 - mae: 0.2116 - val_loss: 0.0171 - val_mae: 0.0998\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0672 - mae: 0.2050 - val_loss: 0.0181 - val_mae: 0.1039\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0674 - mae: 0.2057 - val_loss: 0.0218 - val_mae: 0.1182\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0667 - mae: 0.2048 - val_loss: 0.0189 - val_mae: 0.1064\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0676 - mae: 0.2051 - val_loss: 0.0179 - val_mae: 0.1028\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0667 - mae: 0.2045 - val_loss: 0.0164 - val_mae: 0.0969\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0645 - mae: 0.2008 - val_loss: 0.0222 - val_mae: 0.1155\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0646 - mae: 0.2012 - val_loss: 0.0282 - val_mae: 0.1360\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 107us/step - loss: 0.0649 - mae: 0.2003 - val_loss: 0.0189 - val_mae: 0.1063\n",
      "Fold 6\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 5s 260us/step - loss: 3.0255 - mae: 1.2421 - val_loss: 0.6493 - val_mae: 0.6046\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.5176 - mae: 0.5491 - val_loss: 0.1098 - val_mae: 0.2460\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.2547 - mae: 0.3955 - val_loss: 0.0517 - val_mae: 0.1688\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 2s 110us/step - loss: 0.2016 - mae: 0.3547 - val_loss: 0.0385 - val_mae: 0.1454\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 105us/step - loss: 0.1746 - mae: 0.3298 - val_loss: 0.0330 - val_mae: 0.1395\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.1588 - mae: 0.3147 - val_loss: 0.0301 - val_mae: 0.1295\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 2s 106us/step - loss: 0.1483 - mae: 0.3053 - val_loss: 0.0274 - val_mae: 0.1268\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.1419 - mae: 0.2981 - val_loss: 0.0253 - val_mae: 0.1232\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.1346 - mae: 0.2903 - val_loss: 0.0297 - val_mae: 0.1343\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.1286 - mae: 0.2840 - val_loss: 0.0230 - val_mae: 0.1171\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.1236 - mae: 0.2778 - val_loss: 0.0273 - val_mae: 0.1298\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.1210 - mae: 0.2746 - val_loss: 0.0265 - val_mae: 0.1251\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 2s 99us/step - loss: 0.1127 - mae: 0.2660 - val_loss: 0.0222 - val_mae: 0.1149\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.1094 - mae: 0.2617 - val_loss: 0.0217 - val_mae: 0.1137\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.1077 - mae: 0.2601 - val_loss: 0.0242 - val_mae: 0.1223\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.1040 - mae: 0.2545 - val_loss: 0.0233 - val_mae: 0.1218\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1003 - mae: 0.2509 - val_loss: 0.0219 - val_mae: 0.1159\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0956 - mae: 0.2438 - val_loss: 0.0218 - val_mae: 0.1157\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0942 - mae: 0.2426 - val_loss: 0.0265 - val_mae: 0.1304\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0904 - mae: 0.2375 - val_loss: 0.0208 - val_mae: 0.1129\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0882 - mae: 0.2332 - val_loss: 0.0222 - val_mae: 0.1177\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 1s 70us/step - loss: 0.0865 - mae: 0.2333 - val_loss: 0.0343 - val_mae: 0.1491\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0891 - mae: 0.2356 - val_loss: 0.0196 - val_mae: 0.1079\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 115us/step - loss: 0.0855 - mae: 0.2318 - val_loss: 0.0189 - val_mae: 0.1079\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 110us/step - loss: 0.0854 - mae: 0.2309 - val_loss: 0.0175 - val_mae: 0.1023\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0832 - mae: 0.2272 - val_loss: 0.0175 - val_mae: 0.1021\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0811 - mae: 0.2245 - val_loss: 0.0173 - val_mae: 0.1016\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0797 - mae: 0.2233 - val_loss: 0.0190 - val_mae: 0.1079\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0798 - mae: 0.2234 - val_loss: 0.0195 - val_mae: 0.1057\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0787 - mae: 0.2213 - val_loss: 0.0223 - val_mae: 0.1147\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0777 - mae: 0.2209 - val_loss: 0.0205 - val_mae: 0.1102\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0765 - mae: 0.2195 - val_loss: 0.0224 - val_mae: 0.1201\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0756 - mae: 0.2168 - val_loss: 0.0175 - val_mae: 0.1003\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0750 - mae: 0.2171 - val_loss: 0.0227 - val_mae: 0.1211\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0757 - mae: 0.2181 - val_loss: 0.0187 - val_mae: 0.1059\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0734 - mae: 0.2146 - val_loss: 0.0267 - val_mae: 0.1300\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0726 - mae: 0.2126 - val_loss: 0.0191 - val_mae: 0.1047\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 2s 98us/step - loss: 0.0725 - mae: 0.2132 - val_loss: 0.0202 - val_mae: 0.1117\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0714 - mae: 0.2102 - val_loss: 0.0181 - val_mae: 0.1050\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0710 - mae: 0.2108 - val_loss: 0.0178 - val_mae: 0.1018\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0700 - mae: 0.2096 - val_loss: 0.0182 - val_mae: 0.1045\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0691 - mae: 0.2073 - val_loss: 0.0181 - val_mae: 0.1059\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0681 - mae: 0.2068 - val_loss: 0.0191 - val_mae: 0.1063\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0692 - mae: 0.2074 - val_loss: 0.0200 - val_mae: 0.1092\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0663 - mae: 0.2035 - val_loss: 0.0159 - val_mae: 0.0971\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0666 - mae: 0.2035 - val_loss: 0.0203 - val_mae: 0.1141\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 107us/step - loss: 0.0657 - mae: 0.2029 - val_loss: 0.0193 - val_mae: 0.1060\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 106us/step - loss: 0.0662 - mae: 0.2033 - val_loss: 0.0160 - val_mae: 0.0968\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0651 - mae: 0.2021 - val_loss: 0.0165 - val_mae: 0.0987\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 104us/step - loss: 0.0649 - mae: 0.2015 - val_loss: 0.0168 - val_mae: 0.0988\n",
      "Fold 7\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 3s 182us/step - loss: 2.8443 - mae: 1.2127 - val_loss: 0.6230 - val_mae: 0.5934\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.4688 - mae: 0.5236 - val_loss: 0.0921 - val_mae: 0.2311\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.2351 - mae: 0.3820 - val_loss: 0.0587 - val_mae: 0.1837\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.1947 - mae: 0.3477 - val_loss: 0.0580 - val_mae: 0.1960\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1688 - mae: 0.3249 - val_loss: 0.0356 - val_mae: 0.1453\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.1559 - mae: 0.3119 - val_loss: 0.0322 - val_mae: 0.1395\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.1463 - mae: 0.3027 - val_loss: 0.0431 - val_mae: 0.1638\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.1375 - mae: 0.2931 - val_loss: 0.0342 - val_mae: 0.1483\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.1308 - mae: 0.2869 - val_loss: 0.0318 - val_mae: 0.1403\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.1249 - mae: 0.2802 - val_loss: 0.0258 - val_mae: 0.1253\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.1247 - mae: 0.2800 - val_loss: 0.0271 - val_mae: 0.1302\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.1159 - mae: 0.2692 - val_loss: 0.0242 - val_mae: 0.1210\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.1130 - mae: 0.2656 - val_loss: 0.0276 - val_mae: 0.1306\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.1094 - mae: 0.2619 - val_loss: 0.0242 - val_mae: 0.1207\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.1053 - mae: 0.2567 - val_loss: 0.0273 - val_mae: 0.1320\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0997 - mae: 0.2496 - val_loss: 0.0222 - val_mae: 0.1154\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0965 - mae: 0.2449 - val_loss: 0.0231 - val_mae: 0.1192\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0968 - mae: 0.2451 - val_loss: 0.0213 - val_mae: 0.1131\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0921 - mae: 0.2404 - val_loss: 0.0244 - val_mae: 0.1214\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0915 - mae: 0.2383 - val_loss: 0.0198 - val_mae: 0.1082\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0874 - mae: 0.2333 - val_loss: 0.0223 - val_mae: 0.1173\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0840 - mae: 0.2294 - val_loss: 0.0193 - val_mae: 0.1070\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0838 - mae: 0.2278 - val_loss: 0.0189 - val_mae: 0.1056\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0801 - mae: 0.2237 - val_loss: 0.0198 - val_mae: 0.1087\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0825 - mae: 0.2266 - val_loss: 0.0191 - val_mae: 0.1061\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.0794 - mae: 0.2229 - val_loss: 0.0233 - val_mae: 0.1212\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0796 - mae: 0.2234 - val_loss: 0.0221 - val_mae: 0.1169\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0771 - mae: 0.2190 - val_loss: 0.0197 - val_mae: 0.1097\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 114us/step - loss: 0.0766 - mae: 0.2190 - val_loss: 0.0352 - val_mae: 0.1513\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0759 - mae: 0.2169 - val_loss: 0.0183 - val_mae: 0.1034\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0756 - mae: 0.2169 - val_loss: 0.0251 - val_mae: 0.1239\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0731 - mae: 0.2138 - val_loss: 0.0216 - val_mae: 0.1135\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0744 - mae: 0.2152 - val_loss: 0.0186 - val_mae: 0.1056\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0726 - mae: 0.2129 - val_loss: 0.0195 - val_mae: 0.1074\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0708 - mae: 0.2107 - val_loss: 0.0218 - val_mae: 0.1164\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 2s 102us/step - loss: 0.0700 - mae: 0.2090 - val_loss: 0.0178 - val_mae: 0.1023\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0699 - mae: 0.2087 - val_loss: 0.0182 - val_mae: 0.1023\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0699 - mae: 0.2092 - val_loss: 0.0189 - val_mae: 0.1051\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 2s 89us/step - loss: 0.0695 - mae: 0.2088 - val_loss: 0.0184 - val_mae: 0.1042\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0686 - mae: 0.2076 - val_loss: 0.0175 - val_mae: 0.1005\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0671 - mae: 0.2049 - val_loss: 0.0202 - val_mae: 0.1097\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - ETA: 0s - loss: 0.0669 - mae: 0.205 - 1s 77us/step - loss: 0.0668 - mae: 0.2050 - val_loss: 0.0218 - val_mae: 0.1160\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 2s 94us/step - loss: 0.0673 - mae: 0.2053 - val_loss: 0.0245 - val_mae: 0.1240\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.0648 - mae: 0.2012 - val_loss: 0.0173 - val_mae: 0.1001\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0634 - mae: 0.1992 - val_loss: 0.0176 - val_mae: 0.1016\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0649 - mae: 0.2014 - val_loss: 0.0227 - val_mae: 0.1186\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0640 - mae: 0.1992 - val_loss: 0.0189 - val_mae: 0.1051\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0636 - mae: 0.1999 - val_loss: 0.0296 - val_mae: 0.1406\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0612 - mae: 0.1950 - val_loss: 0.0185 - val_mae: 0.1049\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0626 - mae: 0.1980 - val_loss: 0.0196 - val_mae: 0.1095\n",
      "Fold 8\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 3s 166us/step - loss: 3.1440 - mae: 1.2704 - val_loss: 0.6867 - val_mae: 0.6392\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.5462 - mae: 0.5660 - val_loss: 0.1254 - val_mae: 0.2669\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 2s 97us/step - loss: 0.2820 - mae: 0.4172 - val_loss: 0.0568 - val_mae: 0.1796\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 2s 101us/step - loss: 0.2253 - mae: 0.3741 - val_loss: 0.0397 - val_mae: 0.1498\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.1940 - mae: 0.3472 - val_loss: 0.0351 - val_mae: 0.1421\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 2s 100us/step - loss: 0.1749 - mae: 0.3328 - val_loss: 0.0318 - val_mae: 0.1349\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 2s 90us/step - loss: 0.1643 - mae: 0.3208 - val_loss: 0.0321 - val_mae: 0.1381\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.1562 - mae: 0.3136 - val_loss: 0.0302 - val_mae: 0.1348\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.1479 - mae: 0.3054 - val_loss: 0.0265 - val_mae: 0.1246\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 2s 114us/step - loss: 0.1400 - mae: 0.2967 - val_loss: 0.0253 - val_mae: 0.1225\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1344 - mae: 0.2900 - val_loss: 0.0250 - val_mae: 0.1230\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.1350 - mae: 0.2907 - val_loss: 0.0241 - val_mae: 0.1185\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.1279 - mae: 0.2835 - val_loss: 0.0266 - val_mae: 0.1282\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1226 - mae: 0.2760 - val_loss: 0.0273 - val_mae: 0.1287\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1231 - mae: 0.2774 - val_loss: 0.0264 - val_mae: 0.1243\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.1173 - mae: 0.2716 - val_loss: 0.0268 - val_mae: 0.1262\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1161 - mae: 0.2692 - val_loss: 0.0236 - val_mae: 0.1153\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.1095 - mae: 0.2620 - val_loss: 0.0242 - val_mae: 0.1196\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.1091 - mae: 0.2620 - val_loss: 0.0237 - val_mae: 0.1210\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.1040 - mae: 0.2550 - val_loss: 0.0207 - val_mae: 0.1101\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 2s 86us/step - loss: 0.1057 - mae: 0.2569 - val_loss: 0.0260 - val_mae: 0.1256\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1027 - mae: 0.2540 - val_loss: 0.0204 - val_mae: 0.1087\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0978 - mae: 0.2475 - val_loss: 0.0235 - val_mae: 0.1207\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0986 - mae: 0.2479 - val_loss: 0.0220 - val_mae: 0.1150\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0939 - mae: 0.2422 - val_loss: 0.0197 - val_mae: 0.1057\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0952 - mae: 0.2430 - val_loss: 0.0198 - val_mae: 0.1080\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 2s 81us/step - loss: 0.0907 - mae: 0.2382 - val_loss: 0.0240 - val_mae: 0.1187\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0882 - mae: 0.2350 - val_loss: 0.0216 - val_mae: 0.1130\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0893 - mae: 0.2365 - val_loss: 0.0219 - val_mae: 0.1162\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0872 - mae: 0.2332 - val_loss: 0.0195 - val_mae: 0.1072\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 1s 67us/step - loss: 0.0860 - mae: 0.2319 - val_loss: 0.0209 - val_mae: 0.1133\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0857 - mae: 0.2312 - val_loss: 0.0206 - val_mae: 0.1112\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0832 - mae: 0.2280 - val_loss: 0.0187 - val_mae: 0.1058\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0841 - mae: 0.2289 - val_loss: 0.0222 - val_mae: 0.1124\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 2s 98us/step - loss: 0.0806 - mae: 0.2240 - val_loss: 0.0219 - val_mae: 0.1144\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0799 - mae: 0.2236 - val_loss: 0.0178 - val_mae: 0.1030\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0776 - mae: 0.2209 - val_loss: 0.0181 - val_mae: 0.1030\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0803 - mae: 0.2239 - val_loss: 0.0180 - val_mae: 0.1033\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0769 - mae: 0.2196 - val_loss: 0.0193 - val_mae: 0.1079\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - ETA: 0s - loss: 0.0780 - mae: 0.221 - 1s 71us/step - loss: 0.0781 - mae: 0.2213 - val_loss: 0.0208 - val_mae: 0.1148\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0757 - mae: 0.2170 - val_loss: 0.0203 - val_mae: 0.1091\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0739 - mae: 0.2149 - val_loss: 0.0174 - val_mae: 0.1018\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0743 - mae: 0.2151 - val_loss: 0.0190 - val_mae: 0.1053\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0742 - mae: 0.2158 - val_loss: 0.0287 - val_mae: 0.1301\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0741 - mae: 0.2151 - val_loss: 0.0192 - val_mae: 0.1054\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0705 - mae: 0.2097 - val_loss: 0.0209 - val_mae: 0.1116\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0714 - mae: 0.2115 - val_loss: 0.0221 - val_mae: 0.1143\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0703 - mae: 0.2091 - val_loss: 0.0171 - val_mae: 0.1007\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 2s 82us/step - loss: 0.0700 - mae: 0.2089 - val_loss: 0.0180 - val_mae: 0.1017\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0684 - mae: 0.2059 - val_loss: 0.0169 - val_mae: 0.0979\n",
      "Fold 9\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 4s 197us/step - loss: 3.0262 - mae: 1.2383 - val_loss: 0.6707 - val_mae: 0.6118\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.5129 - mae: 0.5503 - val_loss: 0.1278 - val_mae: 0.2725\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.2658 - mae: 0.4067 - val_loss: 0.0660 - val_mae: 0.1931\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.2121 - mae: 0.3638 - val_loss: 0.0491 - val_mae: 0.1694\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.1893 - mae: 0.3432 - val_loss: 0.0414 - val_mae: 0.1590\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.1727 - mae: 0.3285 - val_loss: 0.0375 - val_mae: 0.1472\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1604 - mae: 0.3154 - val_loss: 0.0272 - val_mae: 0.1247\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.1488 - mae: 0.3038 - val_loss: 0.0496 - val_mae: 0.1764\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.1433 - mae: 0.2998 - val_loss: 0.0268 - val_mae: 0.1246\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.1326 - mae: 0.2880 - val_loss: 0.0257 - val_mae: 0.1241\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1299 - mae: 0.2854 - val_loss: 0.0364 - val_mae: 0.1497\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.1265 - mae: 0.2807 - val_loss: 0.0266 - val_mae: 0.1280\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.1196 - mae: 0.2724 - val_loss: 0.0270 - val_mae: 0.1279\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.1166 - mae: 0.2710 - val_loss: 0.0264 - val_mae: 0.1258\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1164 - mae: 0.2696 - val_loss: 0.0256 - val_mae: 0.1253\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1081 - mae: 0.2611 - val_loss: 0.0228 - val_mae: 0.1137\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.1076 - mae: 0.2587 - val_loss: 0.0247 - val_mae: 0.1230\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.1062 - mae: 0.2576 - val_loss: 0.0260 - val_mae: 0.1255\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.1024 - mae: 0.2534 - val_loss: 0.0240 - val_mae: 0.1206\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1007 - mae: 0.2510 - val_loss: 0.0252 - val_mae: 0.1246\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0985 - mae: 0.2494 - val_loss: 0.0235 - val_mae: 0.1146\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0956 - mae: 0.2443 - val_loss: 0.0226 - val_mae: 0.1132\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0929 - mae: 0.2408 - val_loss: 0.0440 - val_mae: 0.1756\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0921 - mae: 0.2395 - val_loss: 0.0230 - val_mae: 0.1168\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0886 - mae: 0.2357 - val_loss: 0.0238 - val_mae: 0.1212\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0894 - mae: 0.2360 - val_loss: 0.0208 - val_mae: 0.1105\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 1s 69us/step - loss: 0.0870 - mae: 0.2330 - val_loss: 0.0221 - val_mae: 0.1163\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0893 - mae: 0.2358 - val_loss: 0.0315 - val_mae: 0.1400\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0861 - mae: 0.2324 - val_loss: 0.0280 - val_mae: 0.1333\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 1s 77us/step - loss: 0.0829 - mae: 0.2275 - val_loss: 0.0200 - val_mae: 0.1085\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 1s 74us/step - loss: 0.0838 - mae: 0.2294 - val_loss: 0.0222 - val_mae: 0.1126\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.0831 - mae: 0.2278 - val_loss: 0.0195 - val_mae: 0.1062\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0799 - mae: 0.2234 - val_loss: 0.0189 - val_mae: 0.1019\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 1s 71us/step - loss: 0.0809 - mae: 0.2246 - val_loss: 0.0195 - val_mae: 0.1048\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0794 - mae: 0.2233 - val_loss: 0.0193 - val_mae: 0.1062\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0796 - mae: 0.2233 - val_loss: 0.0214 - val_mae: 0.1088\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0781 - mae: 0.2203 - val_loss: 0.0201 - val_mae: 0.1061\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 66us/step - loss: 0.0752 - mae: 0.2170 - val_loss: 0.0228 - val_mae: 0.1188\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0772 - mae: 0.2195 - val_loss: 0.0185 - val_mae: 0.1023\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 68us/step - loss: 0.0746 - mae: 0.2163 - val_loss: 0.0223 - val_mae: 0.1159\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 1s 79us/step - loss: 0.0727 - mae: 0.2125 - val_loss: 0.0205 - val_mae: 0.1111\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0719 - mae: 0.2118 - val_loss: 0.0228 - val_mae: 0.1185\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - 2s 83us/step - loss: 0.0721 - mae: 0.2118 - val_loss: 0.0197 - val_mae: 0.1069\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 1s 51us/step - loss: 0.0701 - mae: 0.2095 - val_loss: 0.0185 - val_mae: 0.1029\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0701 - mae: 0.2102 - val_loss: 0.0189 - val_mae: 0.1013\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.0687 - mae: 0.2077 - val_loss: 0.0188 - val_mae: 0.1035\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0671 - mae: 0.2045 - val_loss: 0.0190 - val_mae: 0.1045\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 84us/step - loss: 0.0680 - mae: 0.2060 - val_loss: 0.0194 - val_mae: 0.1068\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0665 - mae: 0.2043 - val_loss: 0.0210 - val_mae: 0.1113\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0676 - mae: 0.2048 - val_loss: 0.0208 - val_mae: 0.1107\n",
      "Fold 10\n",
      "Train on 18900 samples, validate on 2100 samples\n",
      "Epoch 1/50\n",
      "18900/18900 [==============================] - 2s 114us/step - loss: 2.7970 - mae: 1.2094 - val_loss: 0.7125 - val_mae: 0.6384\n",
      "Epoch 2/50\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.4928 - mae: 0.5363 - val_loss: 0.1017 - val_mae: 0.2480\n",
      "Epoch 3/50\n",
      "18900/18900 [==============================] - 1s 57us/step - loss: 0.2385 - mae: 0.3847 - val_loss: 0.0572 - val_mae: 0.1868\n",
      "Epoch 4/50\n",
      "18900/18900 [==============================] - 1s 50us/step - loss: 0.1869 - mae: 0.3401 - val_loss: 0.0394 - val_mae: 0.1503\n",
      "Epoch 5/50\n",
      "18900/18900 [==============================] - 1s 48us/step - loss: 0.1640 - mae: 0.3208 - val_loss: 0.0373 - val_mae: 0.1489\n",
      "Epoch 6/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.1526 - mae: 0.3087 - val_loss: 0.0597 - val_mae: 0.1950\n",
      "Epoch 7/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1403 - mae: 0.2970 - val_loss: 0.0346 - val_mae: 0.1401\n",
      "Epoch 8/50\n",
      "18900/18900 [==============================] - 1s 59us/step - loss: 0.1345 - mae: 0.2908 - val_loss: 0.0288 - val_mae: 0.1262\n",
      "Epoch 9/50\n",
      "18900/18900 [==============================] - 1s 60us/step - loss: 0.1292 - mae: 0.2835 - val_loss: 0.0274 - val_mae: 0.1260\n",
      "Epoch 10/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.1218 - mae: 0.2760 - val_loss: 0.0300 - val_mae: 0.1337\n",
      "Epoch 11/50\n",
      "18900/18900 [==============================] - 1s 58us/step - loss: 0.1188 - mae: 0.2727 - val_loss: 0.0288 - val_mae: 0.1303\n",
      "Epoch 12/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.1156 - mae: 0.2691 - val_loss: 0.0235 - val_mae: 0.1164\n",
      "Epoch 13/50\n",
      "18900/18900 [==============================] - 1s 56us/step - loss: 0.1116 - mae: 0.2651 - val_loss: 0.0242 - val_mae: 0.1180\n",
      "Epoch 14/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.1069 - mae: 0.2588 - val_loss: 0.0257 - val_mae: 0.1217\n",
      "Epoch 15/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.1019 - mae: 0.2530 - val_loss: 0.0261 - val_mae: 0.1240\n",
      "Epoch 16/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.1003 - mae: 0.2503 - val_loss: 0.0282 - val_mae: 0.1291\n",
      "Epoch 17/50\n",
      "18900/18900 [==============================] - 1s 76us/step - loss: 0.0966 - mae: 0.2460 - val_loss: 0.0217 - val_mae: 0.1106\n",
      "Epoch 18/50\n",
      "18900/18900 [==============================] - 1s 72us/step - loss: 0.0940 - mae: 0.2419 - val_loss: 0.0215 - val_mae: 0.1103\n",
      "Epoch 19/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0897 - mae: 0.2367 - val_loss: 0.0243 - val_mae: 0.1197\n",
      "Epoch 20/50\n",
      "18900/18900 [==============================] - 1s 61us/step - loss: 0.0920 - mae: 0.2392 - val_loss: 0.0251 - val_mae: 0.1191\n",
      "Epoch 21/50\n",
      "18900/18900 [==============================] - 1s 64us/step - loss: 0.0870 - mae: 0.2332 - val_loss: 0.0284 - val_mae: 0.1310\n",
      "Epoch 22/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0868 - mae: 0.2327 - val_loss: 0.0190 - val_mae: 0.1037\n",
      "Epoch 23/50\n",
      "18900/18900 [==============================] - 2s 99us/step - loss: 0.0856 - mae: 0.2312 - val_loss: 0.0212 - val_mae: 0.1100\n",
      "Epoch 24/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0818 - mae: 0.2270 - val_loss: 0.0201 - val_mae: 0.1054\n",
      "Epoch 25/50\n",
      "18900/18900 [==============================] - 2s 96us/step - loss: 0.0813 - mae: 0.2250 - val_loss: 0.0201 - val_mae: 0.1067\n",
      "Epoch 26/50\n",
      "18900/18900 [==============================] - 2s 92us/step - loss: 0.0813 - mae: 0.2258 - val_loss: 0.0292 - val_mae: 0.1363\n",
      "Epoch 27/50\n",
      "18900/18900 [==============================] - 2s 87us/step - loss: 0.0780 - mae: 0.2205 - val_loss: 0.0206 - val_mae: 0.1080\n",
      "Epoch 28/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0782 - mae: 0.2207 - val_loss: 0.0197 - val_mae: 0.1062\n",
      "Epoch 29/50\n",
      "18900/18900 [==============================] - 2s 88us/step - loss: 0.0790 - mae: 0.2220 - val_loss: 0.0192 - val_mae: 0.1054\n",
      "Epoch 30/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0771 - mae: 0.2193 - val_loss: 0.0203 - val_mae: 0.1107\n",
      "Epoch 31/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0752 - mae: 0.2164 - val_loss: 0.0229 - val_mae: 0.1180\n",
      "Epoch 32/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0756 - mae: 0.2178 - val_loss: 0.0182 - val_mae: 0.1024\n",
      "Epoch 33/50\n",
      "18900/18900 [==============================] - 2s 91us/step - loss: 0.0733 - mae: 0.2138 - val_loss: 0.0220 - val_mae: 0.1151\n",
      "Epoch 34/50\n",
      "18900/18900 [==============================] - 2s 80us/step - loss: 0.0743 - mae: 0.2157 - val_loss: 0.0206 - val_mae: 0.1092\n",
      "Epoch 35/50\n",
      "18900/18900 [==============================] - 1s 62us/step - loss: 0.0720 - mae: 0.2120 - val_loss: 0.0190 - val_mae: 0.1065\n",
      "Epoch 36/50\n",
      "18900/18900 [==============================] - 1s 63us/step - loss: 0.0722 - mae: 0.2117 - val_loss: 0.0188 - val_mae: 0.1033\n",
      "Epoch 37/50\n",
      "18900/18900 [==============================] - 1s 73us/step - loss: 0.0708 - mae: 0.2110 - val_loss: 0.0204 - val_mae: 0.1085\n",
      "Epoch 38/50\n",
      "18900/18900 [==============================] - 1s 65us/step - loss: 0.0696 - mae: 0.2094 - val_loss: 0.0175 - val_mae: 0.0978\n",
      "Epoch 39/50\n",
      "18900/18900 [==============================] - 1s 55us/step - loss: 0.0706 - mae: 0.2100 - val_loss: 0.0210 - val_mae: 0.1103\n",
      "Epoch 40/50\n",
      "18900/18900 [==============================] - 1s 75us/step - loss: 0.0685 - mae: 0.2071 - val_loss: 0.0182 - val_mae: 0.1019\n",
      "Epoch 41/50\n",
      "18900/18900 [==============================] - 2s 97us/step - loss: 0.0684 - mae: 0.2068 - val_loss: 0.0210 - val_mae: 0.1106\n",
      "Epoch 42/50\n",
      "18900/18900 [==============================] - 2s 101us/step - loss: 0.0680 - mae: 0.2057 - val_loss: 0.0181 - val_mae: 0.1001\n",
      "Epoch 43/50\n",
      "18900/18900 [==============================] - ETA: 0s - loss: 0.0669 - mae: 0.2054- ETA: 1s - l - 2s 109us/step - loss: 0.0666 - mae: 0.2050 - val_loss: 0.0196 - val_mae: 0.1080\n",
      "Epoch 44/50\n",
      "18900/18900 [==============================] - 2s 95us/step - loss: 0.0659 - mae: 0.2034 - val_loss: 0.0193 - val_mae: 0.1054\n",
      "Epoch 45/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0666 - mae: 0.2044 - val_loss: 0.0204 - val_mae: 0.1108\n",
      "Epoch 46/50\n",
      "18900/18900 [==============================] - 2s 93us/step - loss: 0.0641 - mae: 0.2000 - val_loss: 0.0191 - val_mae: 0.1052\n",
      "Epoch 47/50\n",
      "18900/18900 [==============================] - 2s 102us/step - loss: 0.0642 - mae: 0.2002 - val_loss: 0.0189 - val_mae: 0.1023\n",
      "Epoch 48/50\n",
      "18900/18900 [==============================] - 2s 85us/step - loss: 0.0644 - mae: 0.2001 - val_loss: 0.0177 - val_mae: 0.0994\n",
      "Epoch 49/50\n",
      "18900/18900 [==============================] - 1s 78us/step - loss: 0.0643 - mae: 0.2005 - val_loss: 0.0191 - val_mae: 0.1037\n",
      "Epoch 50/50\n",
      "18900/18900 [==============================] - 1s 54us/step - loss: 0.0628 - mae: 0.1982 - val_loss: 0.0183 - val_mae: 0.1010\n",
      "CV score: 38.94202\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 20, restore_best_weights = True)\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, target)):\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation = \"relu\", input_shape = (train[trn_idx].shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation = \"linear\"))\n",
    "    model.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = [\"mae\"])\n",
    "    \n",
    "    history = model.fit(train[trn_idx], \n",
    "                                target[trn_idx], \n",
    "                                batch_size = batch_size, \n",
    "                                epochs = epochs, \n",
    "                                verbose = 1,\n",
    "                                validation_data = (train[val_idx], target[val_idx]),\n",
    "                                callbacks = [early_stopping])\n",
    "    \n",
    "    oof[val_idx] = model.predict(train[val_idx]).reshape(len(train[val_idx]), )\n",
    "    predictions += model.predict(test).reshape(len(test), ) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_absolute_error(np.expm1(target), np.expm1(oof))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "# mae\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"mae\"], label = \"mae\", marker = \"o\")\n",
    "plt.plot(history.history[\"val_mae\"], label = \"val_mae\", marker = \"o\")\n",
    "#plt.xticks(np.arange())\n",
    "#plt.yticks(np.arange())\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "#plt.title(\"\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.grid(color = 'gray', alpha = 0.2)\n",
    "\n",
    "# loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label = \"loss\", marker = \"o\")\n",
    "plt.plot(history.history[\"val_loss\"], label = \"val_loss\", marker = \"o\")\n",
    "#plt.xticks(np.arange())\n",
    "#plt.yticks(np.arange())\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.title(\"\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.grid(color = 'gray', alpha = 0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出用ファイル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.expm1(predictions)\n",
    "sub_df = pd.DataFrame({\"id\":test_df[\"id\"].values})\n",
    "sub_df[\"y\"] = predictions\n",
    "sub_df.to_csv(\"./output/NN_k-fold10_epoch50_averaging.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
